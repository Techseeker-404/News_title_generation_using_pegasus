{"Author": "Rick Merritt\u00a0", "Date": "06.28.2017", "Keywords": "Advanced Technology, Cloud Computing, Communications And Networking Systems Or Equipment, Computers And Peripherals, Consumer Electronics & Appliances, Design For Test, Design Management, Digital, Graphics, Handsets, ICs, Industry World, Manufacturing, Microprocessor, Mobile, Networking, Open Source, Research & Development, Semiconductor Design & Manufacturing, Semiconductors, Servers, Software/Hardware Development, Standards, Startups", "Article": " SAN JOSE, Calif. \u00e2\u0080\u0094 Baidu updated its open-source benchmark for neural networks, adding support for inference jobs and support for low-precision math.DeepBench provides a target for optimizing chips that help data centers build larger and, thus, more accurate models for jobs such as image and natural-language recognition. The work shows that it\u00e2\u0080\u0099s still early days for neural nets. So far, results running the training version of the spec launched last September are only available on a handful of Intel Xeon and Nvidia graphics processors. Results for the new benchmark on server-based inference jobs should be available on those chips soon. In addition, Baidu is releasing results on inference jobs run on devices including the iPhone 6, iPhone 7, and a Raspberry Pi board. Inference in the server has longer latency but can use larger processors and more memory than is available in embedded devices like smartphones and smart speakers. \u00e2\u0080\u009cWe\u00e2\u0080\u0099ve tried to avoid drawing big conclusions; so far, we\u00e2\u0080\u0099re just compiling results,\u00e2\u0080\u009d said Sharan Narang, a systems researcher at Baidu\u00e2\u0080\u0099s Silicon Valley AI Lab. At press time, it was not clear whether Intel would have inference results for the release today, and it is still working on results for its massively parallel Knights Mill. AMD expressed support for the benchmark but has yet to release results running it on its new Epyc x86 and Radeon Instinct GPUs.  A handful of startups including Corenami, Graphcore, Wave Computing, and Nervana \u00e2\u0080\u0094 acquired by Intel \u00e2\u0080\u0094 have plans for deep-learning accelerators. \u00e2\u0080\u009cChip makers are very excited about this and want to showcase their results, [but] we don\u00e2\u0080\u0099t want any use of proprietary libraries, only open ones, so these things take a lot of effort,\u00e2\u0080\u009d said Narang. \u00e2\u0080\u009cWe\u00e2\u0080\u0099ve spoken to Nervana, Graphcore, and Wave, and they all have promising approaches, but none can benchmark real silicon yet.\u00e2\u0080\u009d The updated DeepBench supports lower-precision floating-point operations and sparse operations for inference to boost performance. \u00e2\u0080\u009cThere\u00e2\u0080\u0099s a clear correlation in deep learning of larger models and larger data sets getting better accuracy in any app, so we want to build the largest possible models,\u00e2\u0080\u009d he said. \u00e2\u0080\u009cWe need larger processors, reduced-precision math, and other techniques we\u00e2\u0080\u0099re working on to achieve that goal.\u00e2\u0080\u009d Next page: Tuning math for lower cost, faster response     Share this:TwitterFacebookLinkedInNext Page "}