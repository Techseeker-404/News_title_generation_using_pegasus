{"Author": "Junko Yoshida\u00a0", "Date": "11.12.2020", "Keywords": "AI, machine learning, neural network, Software", "Article": " You have signed, sealed and delivered your ballot. What are the chances your vote didn\u00e2\u0080\u0099t get counted? In the 2020 presidential election, voting by mail \u00e2\u0080\u0094 a measure expanded by most states amid the pandemic \u00e2\u0080\u0094 has become wildly popular. However, this year, the use of mail-in or absentee ballots \u00e2\u0080\u0094 which are the same\u00c2\u00a0 thing \u00e2\u0080\u0094 became a sharply divided political issue, despite this method\u00e2\u0080\u0099s long history of safety and security. Several states, including Oregon and Utah, operate all-mail elections.  In vote-by-mail, some states use the voter\u00e2\u0080\u0099s signature as an additional layer of security, a measure that poses signature issues. How well trained are the election staff to review signatures? Could the process be politically manipulated? Isn\u00e2\u0080\u0099t signature verification an inexact science? Adding to the debate this year is an uptick in the use of AI-based algorithms in some states and counties. Election officials are deploying AI software as a first pass to expedite the verification process. So, how do we know AI is doing the right thing? How reliable and accurate is the AI algorithm? In the 2018 midterm elections, 1.4 percent of all mail ballots nationally were rejected. Of these, about 64,000 failed because election officials determined that signatures did not match, according to a report issued last month by Stanford-MIT Healthy Elections Project. \u00e2\u0080\u009cThe issue isn\u00e2\u0080\u0099t just the rejection rate,\u00e2\u0080\u009d said Portia Allen-Kyle, civil rights attorney. \u00e2\u0080\u009cThe question is, when we begin to automate signature verification\u00e2\u0080\u00a6 [are] there disproportionate rates of rejection for people of color, voters who are new to voting, voters whose first language is not English or voters with arthritis or some other disabilities?\u00e2\u0080\u009d While the post-mortem on technologies used in this election isn\u00e2\u0080\u0099t available yet, EE Times has decided to look for answers to the following questions:  Who created the AI-based signature verification software? What are the basic technology building blocks? What are the strengths and weaknesses of the AI algorithms? Whose ballots are likely to be rejected by AI-based software? What should we be most concerned about: a) AI software itself or b) its implementation by local officials? People often demand \u00e2\u0080\u009ctransparency\u00e2\u0080\u009d from AI. What exactly are the purveyors of the AI algorithms being asked to disclose?  Whose AI software? Parascript (Longmont, CO) is the top purveyor of AI-based signature verification software currently used in elections. The company claims it offers \u00e2\u0080\u009cproven document capture and recognition solutions.\u00e2\u0080\u009d It applies \u00e2\u0080\u009ccomputer vision and artificial intelligence\u00e2\u0080\u009d to markets that range from banking and finance to healthcare, insurances and now voting. Today, 36 states offer \u00e2\u0080\u009cno-excuse\u00e2\u0080\u009d vote-by-mail. Five states hold elections almost entirely by mail (in addition to Oregon and Utah, the others are Colorado, Hawaii, and Washington). Greg Council, Parascript\u00e2\u0080\u0099s vice president, marketing and product management, told us, \u00e2\u0080\u009cThere are something like 33 States now that default to using some sort of signature matching. Most of it is done manually. But there are technologies such as ours that have gradually caught on.\u00e2\u0080\u009d Fully aware of the public\u00e2\u0080\u0099s suspicions about machine learning, Council noted, \u00e2\u0080\u009cAutomated signature verification, especially within the scope of vote by mail or absentee balloting is more of an assistive automation, rather than a completely autonomous thing.\u00e2\u0080\u009d Election officials are using Parascript\u00e2\u0080\u0099s software \u00e2\u0080\u009cat a very low level of tolerance,\u00e2\u0080\u009d he emphasized, largely because most election officials are very risk averse. Council explained that they only allow a certain percentage of ballots to be automatically processed. A larger percentage will be kicked out for a second and third review, using the output from signature verification as part of the information. Finally, one or two [human] reviewers will examine the signatures. The point is that \u00e2\u0080\u009cthere\u00e2\u0080\u0099s still a reliance on us humans to also participate in this signature review process,\u00e2\u0080\u009d he stressed. Asked for details about how election officials are implementing Parascript\u00e2\u0080\u0099s verification software, it\u00e2\u0080\u0099s clear that Parascript neither knows much, nor has it any influence on the process. Council told us, \u00e2\u0080\u009cIn most cases, we\u2019re not privy to all of the implementation details because we work through partners. These organizations help counties implement the software.\u00e2\u0080\u009d  This episode of EE Times on Air Weekly Briefing features Parascript\u2019s Greg Council and civil rights attorney Portia Allen-Kyle. The United States relies on a patchwork of election laws and practices adopted by different states and counties. The lack of uniform implementation guidelines could result in varying degrees of training and ballot rejections. For example, professional forensic document examiners are typically trained for two to three years. In contrast, election officials get several hours of training, creating room for \u00e2\u0080\u009changing chad\u00e2\u0080\u009d type controversies. For example, are election officials looking for reasons to keep the to validate the signature? Or are they looking for reasons to throw it out? Tipping the balance between leniency and stricter rules is a matter of policy and sometimes a matter of law. Technology building blocks of AI software As with any AI-based software developers, Parascript wants to keep the secret sauce in its algorithms proprietary. \u00e2\u0080\u009cI can\u00e2\u0080\u0099t really divulge all our secrets,\u00e2\u0080\u009d said Council. Council, however, stressed that Parascript\u00e2\u0080\u0099s software doesn\u00e2\u0080\u0099t rely on a single type of algorithm. He described it as \u00e2\u0080\u009corthogonal thinking,\u00e2\u0080\u009d drawing in theory from various and sometimes seemingly unrelated perspectives to achieve new insights. Council added that Parscript has technologies that help deconstruct the shapes of signatures. An example is \u00e2\u0080\u009cXR elements,\u00e2\u0080\u009d which Parascript describes as a \u00e2\u0080\u009crevolutionary approach to recognition that closely approximates the way humans read and write.\u00e2\u0080\u009d \u00c2\u00a0XR elements are 64-character motions that can be combined to form all letters used in handwriting. Suspect and reference signatures are presented as sequences of XR elements and compared, using multiple factors. XR interpretation of the correlation between two signatures (Source: Parascript) To complement the holistic approach of verification, Parascript adopts geometrical analysis, which zeroes in on similar nodes \u2014 or distinctive elements \u2014 of the suspect and reference signatures. Geometrical interpretation of signatures (Source: Parascript) Parascript also uses algorithms to compare signature fragments. Using \u00e2\u0080\u009cfundamentally different principles than the holistic approach, it is very efficient in cases where the holistic approach can\u00e2\u0080\u0099t ensure the required reliability level of a result,\u00e2\u0080\u009d according to the company. Signature fragments comparison (Source: Parascript) Finally, Parascript software is designed to issue \u00e2\u0080\u009ca confidence level\u00e2\u0080\u009d measuring the certainty about the match between the signature presented for verification and the authentic reference signature. Council said that Parascript\u00e2\u0080\u0099s software operates on standard Intel-like CPUs using off-the shelf-hardware. \u00e2\u0080\u009cSo, the requirements really are driven by throughput.\u00e2\u0080\u009d He said its minimum requirements include \u00e2\u0080\u009ca two-core, 3 GHz machine.\u00e2\u0080\u009d With that, you can process signatures in sub-seconds, he added. What trips up AI Fundamental to software-based signature analysis is that comparisons use a similar DPI (dot per inch), a criterion that refers to the number of printed dots contained within an inch of a printed image. Council said all of company\u00e2\u0080\u0099s software is trained at 200-300 DPI. \u00e2\u0080\u009cIt\u2019s not too high in resolution, but it\u2019s not too lossy in terms of resolution. So best practices are to use, to have candidate signatures scanned at the same DPI level.\u00e2\u0080\u009d When election officials take signatures from DMV records, this works OK for manual review of signature verification. But when it\u00e2\u0080\u0099s run through the AI software? Not so much. Signatures from DMV records are typically stored at a lossy 96 DPI, said Council. \u00e2\u0080\u009cYou can use machine learning to correct for that as well,\u00e2\u0080\u009d he noted. Earlier this year, the company indeed had a new software release, \u00e2\u0080\u009cwhich will actually enhance the image, but also adjust it down\u00e2\u0080\u009d for an apples-to-apples comparison. Parascript\u00e2\u0080\u0099s test in correcting two images at different DPIs proved to be very positive in protecting reliability of the software, claimed Council. Is AI software superior? Compared to inexperienced, error-prone human reviewers who might be politically biased, one could argue that using AI software ensures a more reliable outcome.\u00c2\u00a0 This argument parallels one often used by advocates for autonomous vehicles \u00e2\u0080\u0094 that they\u00e2\u0080\u0099re safer because AVs never get fatigued or distracted by texting, and don\u00e2\u0080\u0099t drive drunk. But a similar drawback applies to all AI software: the transparency gap. Accuracy in AI depends on training data sets and the quality of labeled data. Although the machine seems politically neutral, the training data could sneak biases into the software without the AI recognizing it. Allen-Kyle pointed out a widespread bias built into data sets. AI algorithms could be prone to reject young or newer voters not used to signing documents, black people without a government-issued ID (a number \u00e2\u0080\u009cas high as 25 percent\u00e2\u0080\u009d), and voters who have been cut out of the system for years for a number of reasons. Publicly inspectable, verifiable and auditable The first order of business in Allen-Kyle\u00e2\u0080\u0099s opinion is that government officials who adopt AI software should be able to see the data. \u00e2\u0080\u009cIt should be publicly inspectable, verifiable and it should be able to be audited.\u00e2\u0080\u009d AI software companies should let people \u00e2\u0080\u009ccheck the math, look under the hood a little bit, and make sure that there are no groups that are more likely to have false negatives\u00e2\u0080\u00a6or no groups are more likely to have their signature rejected for whatever reason,\u00e2\u0080\u009d she noted. These are the information that public officials \u00e2\u0080\u009cprobably want to know upfront, think through, adjust for and really want to send it back to a drawing board to get a bigger sample.\u00e2\u0080\u009d Equally important is to understand how people interact with the AI software, said Allen-Kyle. For example, if a ballot is initially rejected by AI software, human reviewers might think, \u00e2\u0080\u009cThis is a real fancy software. If it says it doesn\u00e2\u0080\u0099t match, then yeah, I guess it doesn\u00e2\u0080\u0099t match.\u00e2\u0080\u009d It\u00e2\u0080\u0099s unclear whether any amount of training can overcome human deference to the machine, given the brevity and inconsistency of training provided to election workers. While Parascript\u00e2\u0080\u0099s Council stressed that the company\u00e2\u0080\u0099s software works in collaboration with human reviewers, Allen-Kyle argued, \u00e2\u0080\u009cInserting a human into the process doesn\u2019t solve the potential downfalls of the algorithm.\u00e2\u0080\u009d Lack of regulation Above all, advocacy groups worry about an oversight shortage. \u00e2\u0080\u009cTechnology is getting ahead of regulation,\u00e2\u0080\u009d said Allen-Kyle. Noting that the fundamental right to vote is at stake, she expressed concern that public officials are relying on a private company \u00e2\u0080\u009cnot subject to transparency, not subject to public auditing, not subject to other regulations or even monitor the demographics of the data that the algorithm was trained on.\u00e2\u0080\u009d Advocacy groups are demanding a host of protections for AI software used, for example, in pre-trials, she said. Such protections \u00e2\u0080\u009cjust don\u00e2\u0080\u0099t exist\u00e2\u0080\u009d for voter signature verification.      Share this:TwitterFacebookLinkedIn "}