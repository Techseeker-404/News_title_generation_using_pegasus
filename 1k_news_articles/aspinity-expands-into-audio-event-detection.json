{"Author": "Sally Ward-Foxton\u00a0", "Date": "04.16.2021", "Keywords": "AI, Analog ICs, edge AI, voice", "Article": " Analog AI chip startup Aspinity is now targeting acoustic event detection, as well as voice detection, in ultra-low power systems. The company is rolling out an evaluation kit to ease development of acoustic event detection systems in battery-powered devices. Aspinity\u00e2\u0080\u0099s analog AI accelerator chip is used to detect acoustic events at the start of the signal chain while microphone data is still in its analog form, meaning digital systems further downstream can remain in sleep mode until an event is detected. Tom Doyle (Source: Aspinity) \u00e2\u0080\u009cYou can\u00e2\u0080\u0099t duty cycle sound,\u00e2\u0080\u009d Tom Doyle, CEO of Aspinity told EE Times. \u00e2\u0080\u009cYou have to have it all because these are random events and if you miss any piece of them, you break down the accuracy of the system.\u00e2\u0080\u009d Systems listening for voice or audio events therefore have to be always-on. Aspinity hopes to enable always-on battery-powered acoustic event detection systems that can last years, instead of months, on a single charge. Doyle said that Aspinity\u00e2\u0080\u0099s technique can reduce power consumption significantly; since acoustic events like a window break are extremely rare, the rest of the system can remain in sleep mode for the vast majority of the time. Audio and voice  Aspinity\u00e2\u0080\u0099s EVK1 acoustic event detection evaluation kit (Source: Aspinity) The company previously focused on voice detection, where its chip can be used to wake up other parts of the system when voice is detected. Downstream digital processing would be used to analyze the voice, perhaps detecting specific wake words or key words, for example. While the new evaluation kit focuses on acoustic event detection, the same analog AI chip can be used for applications across voice, sound and vibration detection, as well as biological signals such as heart rate detection. The new kit includes AI models for glass break detection and voice detection developed in-house by Aspinity (more acoustic events coming soon). There\u00e2\u0080\u0099s also an Infineon Xensiv IM73A135 low-power analog MEMS microphone which draws just 170 \u00c2\u00b5A. And then there\u00e2\u0080\u0099s Aspinity\u00e2\u0080\u0099s analog AI accelerator chip, which consumes just 30 \u00c2\u00b5W. Analog chip Aspinity\u00e2\u0080\u0099s chip is the heart of its offering, allowing signal capture and analysis to be performed entirely in the analog domain, saving a lot of power versus always-on analog-to-digital conversion and digital processing. Aspinity\u00e2\u0080\u0099s chip uses analog signal processing for feature extraction before handing over to an analog neural network (Source: Aspinity) Based on its reconfigurable analog modular processor (Ramp) technology, Aspinity\u00e2\u0080\u0099s chip features small parallel, continuously operating analog blocks. The chip is entirely analog, without any clocks \u00e2\u0080\u0094 blocks are powered independently when needed. \u00e2\u0080\u009c[Our chip] leverages a couple of different innovations and patents, the idea of non-linear analog circuitry to use in decision-making, and [our] patented non-volatile memory that we use to store biasing parameters or offsets for our circuits, but also use to store weights for our analog neural network,\u00e2\u0080\u009d said Doyle. At the front end, the chip has some sensor interface and signal conditioning blocks which supports different sensor types, including accelerometers, microphones, and even multiple sensors. Feature extraction is \u00e2\u0080\u009cexplicitly analog\u00e2\u0080\u009d \u00e2\u0080\u0094 analog circuits extract information about the signal, known as features, which are fed to the neural network to help it make decisions (whether the sound coming in is voice or not). \u00e2\u0080\u009cIt\u00e2\u0080\u0099s a bit different to other neural networks out there, just because it\u00e2\u0080\u0099s hard to equate everything from the digital domain to the analog domain,\u00e2\u0080\u009d said Aspinity\u00e2\u0080\u0099s chief science officer David Graham, adding that the chip does not use the spiking neural networks sometimes found in neuromorphic systems. David Graham (Source: Aspinity) \u00e2\u0080\u009cWe\u00e2\u0080\u0099re performing computations using a form of analog multiplication and accumulation functions, and we\u00e2\u0080\u0099re storing the [analog] weights in our own analog non-volatile memory,\u00e2\u0080\u009d Graham said. \u00e2\u0080\u009cBasically, we\u00e2\u0080\u0099re performing the vector matrix multiplication that you have in any neural network, but we\u00e2\u0080\u0099re doing it in an analog fashion.\u00e2\u0080\u009d The designer can train their neural network using PyTorch or another training framework, then Aspinity software does the rest. A compression block is included to store the 500 ms of sound before voice is detected (called \u00e2\u0080\u009cpre-roll\u00e2\u0080\u009d) that wake word engines require for inference. This compression technology is also used outside of voice applications, Doyle said. Aspinity\u00e2\u0080\u0099s chip can be used to wake up another device, be that a microcontroller or a dedicated wake word detection chip, or something else. \u00e2\u0080\u009cWhen we do wake something up, as long as it has the bandwidth and the capability to do that next stage of processing, we don\u2019t really care which one it is,\u00e2\u0080\u009d said Doyle. Aspinity has partnered with ST for compatibility with its microcontrollers, for example. The company\u00e2\u0080\u0099s evaluation kit for voice spotting uses an ST microcontroller which runs a wake word engine. \u00e2\u0080\u009cWe are driving more efficiency on the digital end\u00e2\u0080\u00a6 we do want to get into a position where perhaps we can reduce the bill of materials and not have to have an extra inferencing chip with a high-power core in there.\u00e2\u0080\u009d Spin-out  Aspinity\u00e2\u0080\u0099s AnalogML Core chip (Source: Aspinity) Aspinity was founded in 2015 to commercialize research from West Virginia University. Since then, the company has been developing hardware, working with customers to meet their needs. A $2.9-million seed round in 2018 allowed the company to get samples into customer hands in 2019. The company also completed a $5.3-million series A in 2020. For the future, Doyle can \u00e2\u0080\u009cabsolutely\u00e2\u0080\u009d see Aspinity devices in the same package alongside another digital chip. \u00e2\u0080\u009cAnytime you can minimize your packaging, there\u00e2\u0080\u0099s a benefit to the customer, but there\u00e2\u0080\u0099s also the signal integrity issue,\u00e2\u0080\u009d he said. \u00e2\u0080\u009cThere\u00e2\u0080\u0099s a huge opportunity there, in co-locating die and not having to deal with going out of a package and back in. There\u00e2\u0080\u0099s just so many benefits\u00e2\u0080\u00a6 from the design and technical aspects, but also the cost, bill of materials, integration, and ease of integration.\u00e2\u0080\u009d Related articles:\u00c2\u00a0  Aspinity Puts Neural Networks Back to Analog Ramping Up Development of Ultra-Low Power Always-On Sensing Aspinity Raises $5.3M to Deploy Neuromorphic Analog Processing IC Voice evaluation kit leverages analog ML chip      Share this:TwitterFacebookLinkedIn "}