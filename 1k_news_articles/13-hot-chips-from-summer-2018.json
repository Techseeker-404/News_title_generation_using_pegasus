{"Author": "Rick Merritt\u00a0", "Date": "08.30.2018", "Keywords": "Academia, Advanced Technology, Boards, Buses, Communications And Networking Systems Or Equipment, Computers And Peripherals, Consumer Electronics & Appliances, Design Management, Design Reuse And IP, Digital, Events, Graphics, Handsets, Hardware Development, ICs, Industry World, Internet Of Things, Legal Issues, Manufacturing, Microcontroller, Microprocessor, Nanotech, Packaging, PC Board, PCs, Research & Development, Semiconductor Design & Manufacturing, Semiconductors, Servers, SoC, Software, Standards, Startups", "Article": "  CUPERTINO, Calif. \u00e2\u0080\u0094 This year\u00e2\u0080\u0099s Hot Chips hosted 25 talks, 16 of them focused at least in part on chips handling artificial intelligence jobs. They spanned a broad range from ultra-low-power devices for the Internet of Things and smartphones to power-hungry slabs of silicon for the data center. Industry consolidation around the x86 made this microprocessor event less interesting for a few years. But with the rise of machine learning, it\u00e2\u0080\u0099s become a hot spot again for engineers who specialize in chip architectures. Believe it or not, there\u00e2\u0080\u0099s more to the chip world these days than deep learning. One speaker described a contender to replace DRAM and called for more talks on memories at the event given the work in alternative RAMs bubbling under the surface. For its part, Xilinx showed a major new variant of the FPGA, geared for AI and more. And attendees heard a call to action to design a whole new computing architecture grouded in security. Keynoter John Hennessey, chairman of Alphabet, noted that the widely used technique of speculative execution had been vulnerable to side-channel attacks for 20 years before computer architects at Google saw the open door. \u00e2\u0080\u009cIt makes you wonder what else we haven\u00e2\u0080\u0099t noticed \u00e2\u0080\u00a6 its amazing given the complexity of these products that they work so well or work at all,\u00e2\u0080\u009d said Nathan Brookwood, analyst at Insight64 and a veteran Hot Chips attendee. In the following pages, we highlight an array of interesting talks that we did not write about in the immediate aftermath of the event. We start with a handful of them that impressed us as most bold in their ambitions and/or creative in their thinking. Startup Tachyum was, no doubt, the boldest of all, but informal conversations named it the least likely to succeed. It aims to win sockets as a mainstream server processor and an AI accelerator with its Prodigy chip whose cores it claims are \u00e2\u0080\u009cfaster than a Xeon and smaller than an Arm.\u00e2\u0080\u009d The 7-nm 290-mm2  chip with up to 64 cores will tape out next year, delivering up to 2 TFlops at 4 GHz, claims the company. Initially, it will depend on a combination of server software that the company ported and an emulator to run other code. Data center operators are not likely to add a startup\u00e2\u0080\u0099s chip and software to their x86 racks without major performance boosts and lots of testing. Analyst Brookwood expressed skepticism about the startup\u00e2\u0080\u0099s use of VLIW, a technique that Intel failed to master with Itanium. If the chip gains any traction, Tachyum is likely to face patent suits from giants such as Intel, he added. Tachyum\u00e2\u0080\u0099s Prodigy sports nine-stage integer and 14-stage floating-point pipelines. (All images: Hot Chips)   Intel described Cascade Lake, its latest 14-nm Xeon server processor. The company tipped the high-level news on the chip at an event a few weeks ago, but Hot Chips provided more details \u00e2\u0080\u0094 and a dash of controversy. Cascade Lake uses the same mechanical, thermal, and socket interface as Intel\u00e2\u0080\u0099s existing 14-nm Xeon and sports the same core count, cache structure, and I/O speeds. The new bits include 14-nm process tweaks to eke out a bit more performance and less power consumption. In addition, the chip supports a new AI instruction and hardware mitigations for the side-channel attacks exposed by Meltdown/Spectre. But the big news is that Cascade Lakes is the first Xeon with a memory controller that supports Intel\u00e2\u0080\u0099s Optane, aka 3D XPoint memories, opening a door to up to 3 TBytes of main memory per socket as well as gains in read/write speeds over DRAM. An Intel engineer giving the talk would not comment on endurance of the Optane media. However, he did say that the boards use a Jedec DDR4 electrical bus with a proprietary Intel protocol that won\u00e2\u0080\u0099t be available to rivals for the foreseeable future. \u00e2\u0080\u009cI don\u00e2\u0080\u0099t think that will stand a legal challenge,\u00e2\u0080\u009d said Brookwood. \u00e2\u0080\u009cIf I was IBM or AMD and Optane DIMMs became popular in data centers and I couldn\u00e2\u0080\u0099t get them, I\u00e2\u0080\u0099d be a little ticked. Intel commands something like 98% of the server market, and that, in my mind, is a monopoly.\u00e2\u0080\u009d    Intel is leading work at the Storage Networking Industry Association to create a software platform for alternative main memories such as Optane. Click to enlarge.  "}