{"Author": "Junko Yoshida\u00a0", "Date": "12.27.2018", "Keywords": "Asic, Automotive, Cpld, Digital, DSP, Fpga, Industries, Microcontroller, Mission Critical, Pld, Research & Development, SoC, Transportation", "Article": "  PARIS\u00c2\u00a0\u00e2\u0080\u0094 Today, there\u00e2\u0080\u0099s no shortage of questions for executives and engineers at tech and auto companies grappling with the technology and business roadmap of automated vehicles (AVs). Three big unanswered questions, however, stand out.\u00c2\u00a0 Egil Juliussen, director of research for Infotainment and advanced driver-assistance systems (ADAS) for automotive at IHS Markit, laid out the following as the \u00e2\u0080\u009cunanswered questions\u00e2\u0080\u009d that will dog the auto industry in 2019:  \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0 Do we really need lidars? \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0 Are tech/auto companies really ready to collaborate in pursuit of \u00e2\u0080\u009cnetwork effect\u00e2\u0080\u009d for advancements of driving software?\u00c2\u00a0 \u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0\u00c2\u00a0 Will the industry solve the  L2 to L3 handover problems?  Industry observers certainly see a new round of AV partnerships percolating among tech companies, tier ones and car OEMs. And several companies are trying out new technologies, such as ADAM, on the L2 to L3 handover quandary. Speaking of that unimaginable dilemma for human drivers when machines suddenly give control back to them, \u00e2\u0080\u009cexpect the resurgence of interest in driver monitoring systems among tier ones and OEMs at the 2019 Consumer Electronics Show in Las Vegas next month,\u00e2\u0080\u009d Colin Barnden, Semicast Research lead analyst, told us. But, will ADAS cars and robocars really need lidars? Juliussen told us, \u00e2\u0080\u009cWe are beginning to hear this a lot.\u00e2\u0080\u009d The issue follows the emergence of digital imaging radars \u00e2\u0080\u009cthat can do a lot more than they used to,\u00e2\u0080\u009d he explained.  Recommended   Robocar\u2019s 2018 Reverse Puts ADAS in Drive   AEye to fuse camera/lidar data  Against this backdrop, a startup called AEye, based in Pleasanton, Calif., announced last week its first commercial product, \u00e2\u0080\u009ciDAR,\u00e2\u0080\u009d a solid-state lidar fused with an HD camera, for the ADAS/AV market. The idea of autonomous vehicles without lidar has been floating around the tech community for almost a year. The proposition is tantalizing because many car OEMs regard lidars as too costly, and they agree that the lidar technology landscape is far from settled. Although nobody is saying that a \u00e2\u0080\u009clidar-free future\u00e2\u0080\u009d is imminent, many imaging radar technology developers discuss it as one of their potential goals. Lars Reger, NXP Semiconductors\u00e2\u0080\u0099 CTO, for example, told us in November that the company hopes to prove it\u00e2\u0080\u0099s possible. \u00c2\u00a0 AEye, however, moves into the is-lidar-necessary debate from another angle. The startup believes that car OEMs are reluctant to use current-generation lidars because their solutions today depend on an array of independent sensors that collectively produce a tremendous amount of data. \u00e2\u0080\u009cThis requires lengthy processing time and massive computing power to collect and assemble data sets by aligning, analyzing, correcting, down sampling, and translating them into actionable information that can be used to safely guide the vehicle,\u00e2\u0080\u009d explained AEye. But what if AEye uses artificial intelligence in a way that discriminately collects data information that only matters to an AV\u00e2\u0080\u0099s path planning, instead of assigning every pixel the same priority? This starting point inspired AEye to develop iDAR, Stephen Lambright, AEye\u00e2\u0080\u0099s vice president of marketing, explained to EE Times. Indeed, AEye\u00e2\u0080\u0099s iDAR is \u00e2\u0080\u009cdeeply rooted in the technologies originally developed for the defense industry,\u00e2\u0080\u009d according to Lambright. The startup\u00e2\u0080\u0099s CEO, Luis Dussan, previously worked on designing surveillance, reconnaissance, and defense systems for fighter jets. He formed AEye \u00e2\u0080\u009cto deliver military-grade performance in autonomous cars.\u00e2\u0080\u009d Driving AEye\u00e2\u0080\u0099s iDAR development were \u00e2\u0080\u009cthree principles that shaped the perception systems on military aircraft Dussan learned,\u00e2\u0080\u009d according to Lambright: 1) never miss anything; 2) understand that objects are not created equal and require different attention; and 3) do everything in real time. In short, the goal of iDAR was to develop a sensor fusion system with \u00e2\u0080\u009cno need to waste computing cycles,\u00e2\u0080\u009d said Aravind Ratnam, AEye\u00e2\u0080\u0099s vice president of products. \u00c2\u00a0Building blocks of iDAR include 1550nm solid-state MEMS lidar, a low-light HD camera and embedded AI. The system is designed to \u00e2\u0080\u009ccombine\u00e2\u0080\u009d 2D camera \u00e2\u0080\u009cpixels\u00e2\u0080\u009d (RGB) and 3D lidar\u00e2\u0080\u0099s data \u00e2\u0080\u009cvoxels\u00e2\u0080\u009d (XYZ) to provide \u00e2\u0080\u009ca new real-time sensor data type\u00e2\u0080\u009d that delivers more accurate, longer range and more intelligent information faster to AV\u00e2\u0080\u0099s path-planning system, according Ratnam. Notably, what AEye\u00e2\u0080\u0099s iDAR offers is not post-scan fusion of a separate camera and lidar system. By developing an intelligent artificial perception system that physically fuses a solid-state lidar with a hi-res camera, AEye explains that its iDAR \u00e2\u0080\u009ccreates a new data type called dynamic vixels.\u00e2\u0080\u009d By capturing x, y, z, r, g, b data, AEye says that dynamic Vixels \u00e2\u0080\u009cbiomimic\u00e2\u0080\u009d the data structure of the human visual cortex. Partner Content:    "}