{"Author": "Jeff Bier\u00a0", "Date": "02.28.2018", "Keywords": "Accessories, Advanced Technology, Communications And Networking Systems Or Equipment, Computers And Peripherals, Consumer Electronics & Appliances, Design Management, Digital, EELife, Electromechanical, Events, Handsets, Industries, Industry World, Internet Of Things, Manufacturing, Medical Devices & Systems, Mobile, People, Peripherals, Research & Development, Semiconductors, Sensors, Transducers, Video", "Article": "  Jeff Bier: You\u00e2\u0080\u0099re incorporating computer vision into your next generation of products.\u00c2\u00a0How are you thinking about it?  Dean Kamen:  I think computer vision is the next step in the development of key sensor technologies. The world of engineering has depended on feedback to make closed-loop systems work reliably, even when the internal components within the control loop are sloppy. With feedback, you can make things tight; feedback systems make things accurate, simple, cheap and reliable. We've been using all kinds of switches and sensors for feedback for years. Once you can buy a pre-canned computer vision system, and you can get pre-canned software, computer vision will become ubiquitous as a base sensor in many different feedback-driven control systems.\u00c2\u00a0  If you ask the average kid today, where do we use computers? Well, every product they have. Your car has 200 of them. Your light switch has a few. They cost a few cents and they're everywhere. I think computer vision will become that type of standard technology that's used everywhere, and that we think of as a necessary, easy, and appropriate solution to all sorts of things. One of the products you\u00e2\u0080\u0099re working on is the next-generation iBOT agile wheelchair.\u00c2\u00a0How are you envisioning using computer vision there?  We've told the world we want the next generation of iBOT to supply situational awareness to users. Some of the iBOT\u00e2\u0080\u0099s users have visual issues, some have cognitive issues or other physical issues that can make it challenging for them to control the iBOT. So, we want to put something on the iBOT to deal with cases like, \u201cOh, I didn't see that curb,\u201d while you're in a balanced mode during the whole day, or, \u201cI didn't see that stairway,\u201d (that would really ruin your whole day), or, \u201cI backed over the cat,\u201d or, \u201cI clipped the corner of a piece of furniture and I came tumbling out.\u201d\u00c2\u00a0I think putting vision systems with situational awareness and mapping systems on an iBOT could be a great enhancement on future models, and I hope that we can do it quickly and effectively with relatively small devices and low power consumption.   "}