{"Author": "Junko Yoshida\u00a0", "Date": "12.04.2018", "Keywords": "Cloud Computing, Computers And Peripherals, Cpld, Digital, Fpga, Pld, Semiconductors, SoC", "Article": "  Achronix Semiconductor Corp. is rolling out Speedcore Gen4m, its new generation of embedded FPGA IP designed as an AI accelerator to be built into SoCs. Seeking more efficient data acceleration, Achronix\u00e2\u0080\u0099 Speedcore Gen4 targets a broader set of applications including computing, networking and storage systems for packet processing and interface protocol bridging/switching. But the Gen4\u00e2\u0080\u0099s shiniest feature, added to its architecture by Achronix, are Machine Learning Processor (MLP) blocks. By adding MLP to the library of available blocks, Achronix claims that Speedcore Gen 4\u00c2\u00a0\u00e2\u0080\u0094\u00c2\u00a0designed for 7nm process technology\u00c2\u00a0\u00e2\u0080\u0094 \u00e2\u0080\u009cdelivers 300% higher system performance for artificial intelligence and machine learning applications,\u00e2\u0080\u009d compared to Achronix\u00e2\u0080\u0099 own 16nm Speedcore. \u00e2\u0080\u009cMLP blocks are highly flexible, compute engines tightly coupled with embedded memories to give the highest performance/watt and lowest cost solution for AI/ML applications,\u00e2\u0080\u009d Achronix said. Why AI?  These days, there is hardly a single chip company CEO not coveting the AI market.  Robert Blake "}