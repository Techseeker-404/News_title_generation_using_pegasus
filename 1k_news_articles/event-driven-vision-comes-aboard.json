{"Author": "Junko Yoshida\u00a0", "Date": "04.24.2018", "Keywords": "Asic, Automotive, Digital, Europe, Geography, Industries, Mission Critical, SoC, Transportation", "Article": "  MADISON, Wis. \u00e2\u0080\u0094 Capturing \u00e2\u0080\u009cevents\u00e2\u0080\u009d in images by using a bio-inspired approach sounds not just cool but downright futuristic. But how many developers have actually witnessed event-based machine vision technology at work? \u00c2\u00a0\u00c2\u00a0Most developers have heard or read about it, and they might be curious. But they\u00e2\u0080\u0098re stuck on the sideline without hands-on experience with novel non-frame-based machine vision technology.\u00c2\u00a0Prophesee, a Paris-based startup, wants these spectators in the game. The company is rolling out this week a first-of-its- kind reference system for vision system developers to try, test and understand how neuromorphic vision works.\u00c2\u00a0Initial users targeted for Prophesse\u00e2\u0080\u0099s reference design will be \u00e2\u0080\u009cdevelopers of industry automation machines and robotics,\u00e2\u0080\u009d Luca Verre, CEO of Prophesee told EE Times. \u00e2\u0080\u009cOur customers in automotive and IoT systems will also find the reference system useful to characterize [Prophesee\u00e2\u0080\u0099s] sensor performance.\u00e2\u0080\u009d Researchers working at R&D labs and universities will also benefit. But the real key here, Verre explained, is that the reference system will trigger creating \u00e2\u0080\u009can ecosystem\u00e2\u0080\u009d around Prophesee\u00e2\u0080\u0099s event-driven, non-frame-based vision systems. \u00e2\u0080\u009cUnless there is an ecosystem for it, there will not be a revolution.\u00e2\u0080\u009d\u00c2\u00a0\u00c2\u00a0Prophesee\u00e2\u0080\u0099s Onboard reference system will contain a VGA resolution camera integrated with Prophesee\u00e2\u0080\u0099s ASIC, Qualcomm\u00e2\u0080\u0099s quad-core Snapdragon processor running at 1.5GHz, 6-axis Inertial Measurement Unit, a range of connectvitis including USB 3.0, Ethernet, micro-HDMI and WiFi (802.11ac), and MIPI CSI-2. (Source: Prophesee) \u00c2\u00a0The sensor is in a \u00c2\u00be-inch optical format, featuring a 15\u00ce\u00bcm optical pitch. According to Prophesee, the vision sensor offers not only extremely fast vision processing but also a high dynamic range of more than 120 dB. It can capture extremely fast motions, \u00e2\u0080\u009cthanks to its sub-millisecond temporal resolution,\u00e2\u0080\u009d the company said.\u00c2\u00a0\u00c2\u00a0Prophesee claims power efficiency and system latency of \u00e2\u0080\u009cbelow 10ms.\u00e2\u0080\u009d The company previously told us that its sensor comes with operating characteristics of less than 10 mW.\u00c2\u00a0Different from traditional frame-based image sensors For decades, machine-vision system designers have depended on their knowledge and experience of how conventional image sensors capture visual information. Traditional sensors are designed to function at a predetermined frame rate regardless of dynamic scene changes, while each frame conveys information from all pixels, uniformly sampling them at the same time. So, improving the performance of machine vision systems has focused on higher frame rates and higher resolution enabled by new image sensors. \u00c2\u00a0 Prophesee believes it\u00e2\u0080\u0099s time to rethink the paradigm. Unlike traditional frame-based cameras, each pixel in Prophesee\u00e2\u0080\u0099s asynchronous time-based image sensor decides independently to sample parts of a scene at different rates. \u00e2\u0080\u009cEach pixel individually controls its sampling\u00c2\u00a0\u00e2\u0080\u0094 with no clock involved \u00e2\u0080\u0094 by reacting to light, or changes in the amount of incident light it receives,\u00e2\u0080\u009d Christoph Posch, Prophesee\u00e2\u0080\u0099s CTO, once explained to EE Times. As a result, Prophesee\u00e2\u0080\u0099s sensor selects only the most useful and relevant elements of a scene. This cuts power, latency and data processing demands imposed by traditional frame-based systems, according to the company. Prophesee\u00e2\u0080\u0099s sensors are based on what the world has already learned about neuromorphic vision. Human eyes and brains do not record visual information in a series of frames. \u00e2\u0080\u009cHumans capture the stuff of interest \u00e2\u0080\u0094 spatial and temporal changes \u00e2\u0080\u0094 and send that information to the brain very efficiently,\u00e2\u0080\u009d Ryad Benosman, Prophesee\u00e2\u0080\u0099s co-founder, once told EE Times.\u00c2\u00a0 With an image sensor not bound by frames, Verre explained, \u00e2\u0080\u009cOur technology will not have to miss important events that might have happened between frames.\u00e2\u0080\u009d   Turning skeptics into believers Asking vision-system engineers to forsake the sacred frame and start using an event-driven image sensor to build new systems is a tough proposal. After a meeting with Bosch in Stuttgart, Germany, Verre, who was on the phone with us in Germany, explained, \u00e2\u0080\u009cIt\u00e2\u0080\u0099s a proposal difficult to accept for many engineers.\u00e2\u0080\u009d  Prophesee reference system "}