{"Author": "Sally Ward-Foxton\u00a0", "Date": "12.03.2020", "Keywords": "AI, artificial intelligence, Cloud Computing, data center, processor accelerators", "Article": " Amazon Web Services (AWS) has invested in Habana Gaudi AI training chips for its cloud offering, a big win for the Intel-owned startup. During the keynote speech at AWS\u00e2\u0080\u0099 re:Invent conference, CEO Andy Jassy also announced that the company has developed its own AI training chip, AWS Trainium. A Habana AI training card with its Gaudi chip. Each AWS EC2 instance will feature 8 of these (Image: Habana Labs) Cloud providers have been cautious so far when it comes to investing in third-party chips with new compute architectures for AI acceleration, preferring to develop their own specialized processors instead (Google TPU, Baidu Kunlun, Alibaba Hanguang, AWS Inferentia). The exceptions are the Graphcore chips available in Microsoft\u00e2\u0080\u0099s Azure cloud (though these are prioritized for customers who are \u00e2\u0080\u009cpushing the boundaries of machine learning\u00e2\u0080\u009d) and the Groq accelerators available with cloud service provider Nimbix (for \u00e2\u0080\u009cselected customers\u00e2\u0080\u009d only). Today\u00e2\u0080\u0099s news therefore makes Habana\u00e2\u0080\u0099s Gaudi instances at AWS the only major rollout of a brand new third-party compute architecture in the cloud to date. SPONSORED | How to avoid HPC data traffic jams Jassy said in his keynote that AWS\u00e2\u0080\u0099 aim is to provide a better price-performance option for AI training workloads than GPUs, and that Habana Gaudi accelerators contributed to that cost reduction for customers. In AWS\u00e2\u0080\u0099 internal tests, price-performance metrics for Habana Gaudi-based EC2 instances were up to 40% better than for current GPU-based EC2 instances on AI workloads, he said. SPONSORED | Norelsys NS1021 offers novel USB 2.0 extension solution Habana Labs, now part of Intel, is an Israeli startup based in Tel Aviv. The company\u00e2\u0080\u0099s Gaudi AI training chip, launched in 2019, has eight VLIW SIMD (very long instruction word, single instruction multiple data) vector processor cores, which it calls tensor processor cores (TPC), and 32GB HBM2 (high bandwidth memory, second generation) memory. It also has on-chip RoCE (remote direct memory access over Converged Ethernet) communications for scaling to very large systems. Habana\u2019s Gaudi chip has eight tensor processor cores (TPC) (Image: Habana Labs) AWS will offer Gaudi-based EC2 instances in the first half of 2021. Each 8-card Gaudi EC2 instance can process about 12,000 images-per-second training ResNet 50 on TensorFlow. A next-generation 7-nm version of Gaudi is currently in the works, according to the Habana. AWS Trainium Jassy also announced AWS\u00e2\u0080\u0099 own training chip, Trainium, in a bid to push AI training costs below even what Habana hardware can offer. While he didn\u00e2\u0080\u0099t give away much detail, Jassy hinted that AWS plans to offer Trainium instances at the lowest cost in the cloud for training, and that each instance will offer a hefty TFLOPS performance figure. This is the second custom AI accelerator chip AWS has designed, joining Inferentia, which is designed for AI inference workloads. Inferentia is based on custom Neuron cores with substantial on-chip memory. Trainium AI training chips will use the same Neuron software development kit (SDK) as Inferentia. Trainium instances will be available in 2021. Related Articles:\u00c2\u00a0  Special Project: Intelligence at Hyper-Scale AI Chip Menu Expands for Data Centers Can AI Accelerators Green the Data Center? Hyper-scale Infrastructure Services Accelerate      Share this:TwitterFacebookLinkedIn "}