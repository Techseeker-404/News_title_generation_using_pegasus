{"Author": "Chuck Byers, OpenFog Consortium\u00a0", "Date": "09.27.2018", "Keywords": "Associations, Communications And Networking Systems Or Equipment, Computers And Peripherals, Design Management, Hardware Development, Industry World, Internet Of Things, Networking, Research & Development, Semiconductors, Software, Standards", "Article": "  Fog computing was conceived as a way to enable applications in high-throughput, high-compute ecosystems that require real-time processing. In the world of the Internet of Things, fog is already supporting deployments on a global scale. The OpenFog Consortium defines fog computing as: \u00e2\u0080\u009cA horizontal, system-level architecture that distributes computing, storage, control and networking functions closer to the users along a Cloud-to-Thing continuum.\u00e2\u0080\u009d \u00c2\u00a0    Fog is closely related to (and sometimes used as a synonym for) edge computing. But fog is typically a bit more hierarchal, serves a more diverse set of vertical markets and provides more cloud-like service models than traditional edge deployments. Here are five pieces of advice for building fog networks we will elaborate on at Fog World Congress: Select applications carefully  In IoT, for example, applications are sometimes difficult to predict or pin down.\u00c2\u00a0 It is often helpful to define the application space of a network or network element in terms of a three-layer taxonomy of the vertical market served, the use cases in those verticals and the specific applications within those use cases. Fog nodes are fundamental processing elements that enable high-compute operations in close proximity to end nodes. Fog nodes may serve multiple verticals, use cases or applications in an efficient, combined network. Once these high-level requirements are well understood, the design of the network and its elements can commence. Partition workloads  Fog offers unique partitioning options for complex software-based systems using a deep hierarchy of processing, networking and storage resources from the cloud to IoT endpoints. With several layers of fog nodes potentially in a deployment, finding a balance of the optimal layer in the hierarchy to host functions is an interesting challenge.  In general, choosing to run algorithms or locate storage resources higher in the hierarchy will result in higher scalability and lower cost. On the other hand, nodes lower in the hierarchy can offer much lower latency and better system-level reliability and security. The goal is to map your applications onto processors and storage arrays throughout the hierarchy in a way that meets all the system\u00e2\u0080\u0099s requirements. Sometimes, this may call for splitting things up, for example by running parts of an analytics algorithm in different fog layers. In other cases, you may need to implement a multi-level, cache-like storage structure distributed across different levels of nodes.   Fog nodes can include compute, storage and network resources and live at multiple levels of a hierarchy.   Click to enlarge. (Source: OpenFog)   Securty is pervasive  Entire books and conferences are devoted to the security of IoT networks.\u00c2\u00a0 Using fog techniques can both complicate and enhance the security properties of IoT networks. More intelligent nodes, perhaps in a multi-layer hierarchy, require more crypto processors and keys, more complex security policies and more attention to potential threats.  However, in many cases, the advantages of fog networks make them worth the trouble. In fog, data from IoT sensors can be analyzed and crypto processed close to its source, preventing the need to send potentially sensitive data all the way to the cloud. Fog nodes can be geographically close to the sources and users of the data, reducing the possibilities of attack from hackers on other continents Orchestraton and management  It is going to take considerable effort to install, configure, download and commission large networks of fog nodes. Once operational, these networks require constant monitoring and frequent updating.  Complex orchestration processes manage fog-based resources and assign workloads to them. They also manage their quick reconfiguration in case of overloads or failures.  IoT networks with tens of billions of IoT endpoint devices will probably end up being supported by tens of millions of fog nodes. Unless these management and orchestration processes are highly automated, the world simply won\u00e2\u0080\u0099t have enough \u00e2\u0080\u009cswivel chair\u00e2\u0080\u009d folks to operate these networks. Measure lifecycle costs of ownership  You can\u00e2\u0080\u0099t decide to deploy fog networks based solely on their initial cost. While purchase and installation cost will be significant, other costs need to be factored in to the equation such as ongoing maintenance, periodic hardware and software updates, energy consumption, and decommissioning costs.\u00c2\u00a0 Be careful about this step given the fact that many fog nodes will have a 10-20 year life in the field. Using techniques described in this article and others to be presented at next week\u00e2\u0080\u0099s Fog World Congress in San Francisco, engineers can serve a multitude of emerging applications that can benefit from fog techniques. When you\u00e2\u0080\u0099re ready to get started, ping us at the OpenFog Consortium and we\u00e2\u0080\u0099ll point you in the right direction. \u2013Charles C. Byers is a system architect at Cisco and chair of the OpenFog Consortium\u00e2\u0080\u0099s architecture work group.  "}