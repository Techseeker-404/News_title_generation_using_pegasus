{"Author": "Colin Barnden\u00a0", "Date": "04.23.2018", "Keywords": "Automotive, Industries, Mission Critical, Transportation", "Article": "  Early in my analyst career a colleague told me \u00e2\u0080\u009cThere are only two types of statistics, those you look up and those you make up\u00e2\u0080\u009d. Hold that thought while considering the statistical validity of Tesla\u00e2\u0080\u0099s declaration that if you are driving a Tesla equipped with Autopilot hardware, you are 3.7 times less likely to be involved in a fatal accident. Note the decimal point. Based on the current total of zero fatalities, I could therefore argue that GM Super Cruise is infinitely safer than Autopilot\u00e2\u0080\u0093or I could just say that neither Autopilot nor Super Cruise has yet covered sufficient miles for statistics to be meaningful. As Mark Twain observed \u00e2\u0080\u009cThere are three kinds of lies: lies, damned lies, and statistics.\u00e2\u0080\u009d Following the Uber and Tesla accidents last month, thousands of articles and blogs have been written comparing the record of AI-driven vehicles with human drivers. Let us be clear, human drivers are involved in too many accidents, but they also cover many miles. However the commentary about the Uber and Tesla accidents overlooks a crucial comparison: Human drivers have short attention spans, slow reaction times and good situational awareness; AI computers have infinite attention spans, fast reaction times and poor situational awareness. It doesn\u00e2\u0080\u0099t matter how many tens of thousands of dollars of sensors and GPUs are fitted to an autonomous vehicle if the AI software cannot understand the context of what it sees and react accordingly. The Uber crash footage presents this issue both graphically and tragically. Autonomous driving thus has a software problem and human driving a distraction problem\u00e2\u0080\u0093which of these can be solved first is the trillion dollar question. Humans are not best suited to the repetitive and typically uneventful nature of driving. Through a combination of factors such as boredom, distraction and fatigue, some drivers wind up passing countless miles on the freeway looking at their cellphone or entertainment system\u00e2\u0080\u0093or driving while drowsy\u00e2\u0080\u0093all the while supposedly in control of two tons of metal traveling at sixty miles or more an hour. Here's another statistic: 90 percent of all light vehicles in use on our roads and highways have no automated or assisted driving features at all\u00e2\u0080\u0093otherwise known as SAE Level 0. So rather than jumping straight to AI, Semicast advocates making human drivers into better drivers, for example with the mandatory installation of autonomous emergency braking and steering (AEB/AES) and camera-based driver monitoring systems from companies such as FotoNation, Seeing Machines and Smart Eye. Aftermarket solutions from suppliers such as EDGE3 Technologies and Guardian also exist for this technology to be installed in trucks and buses. These changes alone would be a great start to reducing fatalities and making our roads and highways safer.\u00c2\u00a0 Better still, these technologies are cheap enough for immediate mass market adoption, are well proven and have no liability issues. Many of the warnings from a September 2017 NTSB report titled \u00e2\u0080\u0098Driver Errors, Overreliance on Automation, Lack of Safeguards, Led to Fatal Tesla Crash\u00e2\u0080\u0099 would appear to have been forgotten or ignored. In Semicast\u00e2\u0080\u0099s view, both proper selection criteria for the human safety driver and the mandatory use of driver monitoring systems in all semi-autonomous vehicles are highly likely to be recommended in the NTSB\u00e2\u0080\u0099s accident reports for the Uber and Tesla crashes. In a blog post on March 30th, Tesla wrote \u00e2\u0080\u009cThe safety of our customers is our top priority.\u00e2\u0080\u009d In response NTSB Chairman Robert Sumwalt stated \u00e2\u0080\u009cMake safety a value, not a \u00e2\u0080\u0098top priority\u00e2\u0080\u0099. Priorities change. Values don\u00e2\u0080\u0099t, not without a lot of wrangling.\u00e2\u0080\u009d   In the ensuing public fallout, Tesla wrote in a blog \u00e2\u0080\u009cIt\u00e2\u0080\u0099s been clear in our conversations with the NTSB that they\u00e2\u0080\u0099re more concerned with press headlines than actually promoting safety.\u00e2\u0080\u009d As Tesla and other tech-focused members of the autonomous driving community seem determined to discover, the NTSB does not promote  safety. The NTSB is  safety. The law applies to billionaires and tech giants too. \u2014 Colin Barnden is principal analyst at Semicast Research (@semicast_res) and has covered the semiconductor and electronics industry for twenty five years. His focus is on the automotive and industrial sectors.  "}