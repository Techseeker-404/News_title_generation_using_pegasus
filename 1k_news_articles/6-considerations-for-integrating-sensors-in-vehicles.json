{"Author": "Anne-Fran\u00c3\u00a7oise Pel\u00c3\u00a9\u00a0", "Date": "10.22.2020", "Keywords": "ADAS, autonomous vehicles, Lidar, Radar, Sensors", "Article": " There may never be one, single, most-effective way to implement sensing technology for assisted driving systems (ADAS) and autonomous vehicles (AV). The magic number might instead be six \u00e2\u0080\u0094 as in six fundamental considerations that every auto maker will decide how to achieve in its own way, which will lead each to creating its own unique approach to integrating sensors in future vehicles.\u00c2\u00a0 At the closing session of the AutoSens Brussels 2020 virtual conference, a panel of experts debated the right sensor mix and how to make sure design never compromises safety \u00e2\u0080\u0094 and vice versa.   What does it take to make cars see better? It\u00e2\u0080\u0099s complicated. Multiple sensing modalities, faster processing power in the vehicle brain, new car architecture with updated in-vehicle network, self-cleaning sensors, common sense layer and a lot more.   The panelists were Patrick Denny, senior expert for vision systems and advanced driver-assistance systems at automotive embedded supplier Valeo; Paul-Henri Matha, technical leader at Volvo Car Corp.; Robert Stead, managing director at Sense Media Group; and Carsten Astheimer, director of design firm Astheimer Ltd. EE Times Europe also reached out to Pierrick Boulay, technology and market analyst at Yole D\u00c3\u00a9veloppement (Lyon, France), for Yole\u00e2\u0080\u0099s insights on the adoption and usage of various sensor types in automotive systems.  Getting the number right More and more sensors are being deployed throughout the vehicle to address safety concerns proactively. How many sensors do we have in cars today, and how many do we need to progress to further levels of autonomy? \u00e2\u0080\u009cIf we take into account sensors for ADAS \u00e2\u0080\u0094 ultrasonic, radar, camera for sensing, camera for viewing, and LiDAR \u00e2\u0080\u0094 we estimate that a vehicle has between 10 and 20 sensors, depending on the type of vehicle,\u00e2\u0080\u009d Yole\u00e2\u0080\u0099s Boulay told EE Times. Naturally, high-end vehicles embed more sensors than low-end vehicles or those in the middle of the performance and feature range. Sensors will be pivotal for unlocking high automation levels, and the number and type of sensors are expected to increase. \u00e2\u0080\u009cWe expect that 35 to 40 sensors will be implemented for these automation levels,\u00e2\u0080\u009d said Boulay. \u00e2\u0080\u009cSensors will be more specific in that we will see sensors for short-, mid-, and long-range applications. One sensor will not be able to cover all applications. Each application or use case will have its specifications and requirements in terms of sensors.\u00e2\u0080\u009d The increasing number of sensors is only the tip of the iceberg. Sensors generate a ton of data, and systems are heavily limited by the processing power. Moving forward, having enough computing power to process all the data generated by these sensors will be a key feature, said Boulay. \u00e2\u0080\u009cWhile typical ADAS systems using Intel-Mobileye chips were doing the leap between 0.25 TOPS [10\u00c3\u0097 the performance of a high-end laptop] and 2.5 TOPS for the new EyeQ4 chip, robotic cars are already beyond 250 TOPS,\u00e2\u0080\u009d he said. Eventually, \u00e2\u0080\u009cthe E/E [electric/electronic] architecture of a vehicle will need to change from a distributed architecture to a centralized architecture with domain controllers, able to manage the fusion of raw data coming from the sensors.\u00e2\u0080\u009d So the more sensors, the merrier? \u00e2\u0080\u009cSome may think this, but the number of sensors in cars will not increase indefinitely, for cost or integration reasons,\u00e2\u0080\u009d said Boulay, who expects the numbers of sensors for automation to plateau at some point. \u00e2\u0080\u009cThe main difference will be at the software level and the capacity of companies to process the enormous quantity of data efficiently. Some OEMs, like Tesla, are still not using LiDAR and are betting on the combination of sensors and AI computing to achieve high automation levels.\u00e2\u0080\u009d Objectively, \u00e2\u0080\u009csome OEMs will do better than others with fewer sensors, and the difference will be at the software and computing levels,\u00e2\u0080\u009d he added. Optimizing the mix  A vehicle might be driving under a big blue sky one moment and through a rain shower the next. Sensors need to be constantly available to measure and monitor variables. An efficient way to enhance availability is by deploying redundant sensors to compensate for possible failures. \u00e2\u0080\u009cThere has to be more than one way of looking at the environment,\u00e2\u0080\u009d Valeo\u00e2\u0080\u0099s Denny said during the panel session. \u00e2\u0080\u009cWhen you are in complete darkness or you have terrible weather conditions, you need a variety of modalities and functions to work together.\u00e2\u0080\u009d Sensors help in situations where human vision is at a disadvantage, and the diversity of sensors is what makes the car reliable in all weather and light conditions. \u00e2\u0080\u009cCameras are good during the daytime,\u00e2\u0080\u009d said Boulay, whereas at night or in the fog or rain, \u00e2\u0080\u009cother sensors will not be \u00e2\u0080\u0098blind\u00e2\u0080\u0099 [like cameras], and the vehicle will still be able to move, even if it is in a degraded mode.\u00e2\u0080\u009d  Recommended The Button Revolution Is Here | On Succession | The Internet of IoT   Ensuring the right placement  Just like human senses, sensors must be strategically positioned to feed back information on the car\u00e2\u0080\u0099s surroundings continuously. But there are technical limitations to where the sensors can be placed. Condensation in a headlamp, for example, can prevent LiDARs from working. In snow or cold weather, frost can lead to a sensor malfunction. Infrared sensors cannot see through glass and cannot be put behind a windscreen. Similarly, painting over an ultrasonic sensor may alter its acoustic properties, said Denny. The power consumption of sensors is also a key challenge, said Volvo\u00e2\u0080\u0099s Matha. \u00e2\u0080\u009cEach sensor consumes between 1 and 10 W. If you add all sensors for ADAS functionalities, you can reach 100 or 200 W, and up to 4 g of CO2. We have to reduce the power consumption. [For example], perhaps the functionality of the sensor will not be active all the time.\u00e2\u0080\u009d Thermal management is another constraint to consider. Behind a windshield, temperature can reach 90\u00c2\u00b0C, and appropriate sensors may not be available, said Matha. \u00e2\u0080\u009cIf you put them in another area, in headlamps, for instance, we have some cooling systems, but it\u00e2\u0080\u0099s complex and expensive.\u00e2\u0080\u009d Simulations and driving tests can help determine the best position for a sensor, the panelists said. Above all, said Yole\u00e2\u0080\u0099s Boulay, \u00e2\u0080\u009cthe position of sensors is closely related to the use cases targeted by OEMs. From what we see currently on vehicles that implement LiDAR for automated driving on highways, the LiDAR is in a central position, almost aligned with the ADAS camera and the long-range radar. For other use cases, like parking or city driving, the position of these LiDAR units will be different and are expected to be on the side or the corners of vehicles.\u00e2\u0080\u009d Integrating aesthetically  Volvo cars currently integrate 20 types of sensors, said Matha. Many of them are totally hidden. On the Volvo XC90, for instance, the forward parking camera is in the grille, while the side cameras are positioned in each door mirror and the backward-facing camera is fitted above the registration plate. \u00e2\u0080\u009cWe can integrate sensors and make them look beautiful,\u00e2\u0080\u009d Matha said. Front-facing camera in the Volvo XC90 (Source: Volvo) But do we necessarily need to hide the sensors? Can\u00e2\u0080\u0099t they be a feature? For Astheimer, if the car is an intelligent product, it should look like it, and \u00e2\u0080\u009ceverything shouldn\u00e2\u0080\u0099t be hidden away.\u00e2\u0080\u009d Sensors are small enough to be completely integrated and almost unnoticeable now. However, as we approach full autonomy, with cars driving themselves, some sensors \u00e2\u0080\u009cwill need to be extremely prominent.\u00e2\u0080\u009d A 360\u00c2\u00b0 LiDAR will need to have full visibility, and its position will accept no compromise. More important, Astheimer highlighted the need for designers and engineers to work together to make sensors fit the identity of the vehicle. The Deliver-E, an electric delivery vehicle prototype co-developed by Warwick Manufacturing Group (WMG), the University of Warwick, and Astheimer, integrates cameras in the sides of the vehicle and places the LiDAR prominently in the back of the car. Asked about the pertinence of concentrating sensors in an external pod, Boulay cited Magneti Marelli\u00e2\u0080\u0099s Smart Corner, which can accommodate sensors such as LiDARs, radars, cameras, and ultrasonics, as well as LED-based lighting features like adaptive beam and digital light processing. \u00e2\u0080\u009cIt could be easier for OEMs to integrate these pods during the manufacturing process, but in the case of an accident, the cost to repair or change these pods for insurance or consumers would be extremely high,\u00e2\u0080\u009d he said. \u00e2\u0080\u009cA balance will have to be found between integration, reparability, and cost.\u00e2\u0080\u009d Reducing cognitive overload The human-machine interface (HMI) not only bridges the driver and the car but also connects the driver with the outside world. The risk is that the driver gets distracted by all the functionalities and misses out on vital driving information. Volta Trucks\u00e2\u0080\u0099 Zero electric delivery truck (Source: Volta Trucks) Engaged in the design of Volta Trucks\u00e2\u0080\u0099 Zero electric delivery truck, Astheimer realized the importance of enhancing the driver\u00e2\u0080\u0099s vigilance. \u00e2\u0080\u009cIn London, although heavy traveling vehicles account for less than 4% of overall traffic, they are responsible for over 50% of vulnerable-road\u00e2\u0080\u0093user deaths, i.e., pedestrians and cyclists,\u00e2\u0080\u009d he said. There are two main reasons for that: the lack of direct visibility and the cognitive overload. \u00e2\u0080\u009cCognitive overload is a massive issue,\u00e2\u0080\u009d said Astheimer. \u00e2\u0080\u009cWe need to make sure ECUs [electronic control units] and CAN [controller area network] systems can read the right signals and display information in the clearest and most simplified way possible, whether it\u00e2\u0080\u0099s tactile, audio, or visual.\u00e2\u0080\u009d Making safety cool  Referencing a panel comment at an earlier AutoSens Conference, Stead asked the panelists whether \u00e2\u0080\u009cmaking safety cool\u00e2\u0080\u009d is the key to selling connected cars. \u00e2\u0080\u009cWe do business with safety,\u00e2\u0080\u009d said Matha. \u00e2\u0080\u009cOur customers want safety, and we can do safety only with sensors. So we need to make beautiful cars with sensors.\u00e2\u0080\u009d There is another dimension to consider. Users need to understand the level of intelligence of their own cars to maintain their alertness to road users and their surroundings. \u00e2\u0080\u009cBy making the product safer and safer, you\u00e2\u0080\u0099re distancing the driver away from what the vehicle is doing,\u00e2\u0080\u009d said Astheimer. \u00e2\u0080\u009cIn adding levels of autonomy onto the vehicle, you are aiding the driver with the simple things, but you are making the difficult things more difficult to do. The driver is no longer attentive as the vehicle does more and more.\u00e2\u0080\u009d It is essential that the sensors, and the feedback from them, help the driver maintain awareness of what is going on \u00e2\u0080\u009crather than just cocooning him from the outside world,\u00e2\u0080\u009d\u00c2\u00a0Astheimer said.   A new book, AspenCore Guide to Sensors in Automotive: Making Cars See and Think Ahead, with contributions from leading thinkers in the safety and automotive industries, heralds the industry\u00e2\u0080\u0099s progress and identifies the engineering community\u00e2\u0080\u0099s remaining challenges.  It\u00e2\u0080\u0099s available now at the\u00c2\u00a0EE Times bookstore.  \u00a0     Share this:TwitterFacebookLinkedIn "}