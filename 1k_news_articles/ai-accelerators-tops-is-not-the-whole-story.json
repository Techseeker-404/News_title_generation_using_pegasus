{"Author": "Sally Ward-Foxton\u00a0", "Date": "12.09.2019", "Keywords": "Asic, Digital, Fpga, Semiconductors", "Article": " In the world of AI accelerators, chip performance is frequently quoted in tera operations per second, or TOPS, for a given algorithm. But there are many reasons why this may not be the best figure to look at. \u00e2\u0080\u009cWhat customers really want is high throughput per dollar,\u00e2\u0080\u009d said Geoff Tate, CEO of AI accelerator company Flex Logix. Geoff Tate (Image: Flex Logix) Tate explained that having more TOPS doesn\u2019t necessarily correlate with higher throughput. This is particularly true in edge applications where the batch size is 1. Applications such as data centers may increase their throughput by processing multiple inputs in parallel using larger batches (since they have TOPS to spare), but this is not often suitable for edge devices. For example, Tate compared Flex Logix\u00e2\u0080\u0099 InferX X1 device with a market-leading GPU device. While the GPU offers three to four times the throughput, with 10x the TOPS, it uses eight times the number of DRAMs. Tate argued that this makes Flex Logix\u00e2\u0080\u0099 architecture a lot more resource-efficient. Tate\u00e2\u0080\u0099s proposed metric, throughput per dollar, sounds sensible but in practice, it\u00e2\u0080\u0099s not always easy to find reliable cost information for products to allow direct comparisons. Factors such as how much DRAM is required, or how much silicon area a particular chip has can be an indicator of cost, but are by no means precise. Flex Logix\u00e2\u0080\u0099 InfereX X1 device will tape out before the end of 2019. It will offer around 8.5 TOPS (Image: Flex Logix) ResNet-50 Another problem with TOPS as a metric is that it\u00e2\u0080\u0099s often measured when running ResNet-50. \u00e2\u0080\u009cResNet-50 is not the benchmark that customers care about, but it is the one that people report the most often,\u00e2\u0080\u009d Tate said. \u00e2\u0080\u009cThe reason it\u2019s not very relevant is it uses very small images.\u00e2\u0080\u009d Now largely seen as out of date, ResNet-50 has been around for some time and has become a de facto standard for quoting TOPS figures. There are good reasons for continuing to use it as a standard; these include trying to keep all scores at least partly comparable going forward, and for keeping this de-facto standard accessible to all types of devices (even tiny ones). However, it is not adequate to really challenge today\u00e2\u0080\u0099s huge chips built for data center inference, nor to show off what they can do. Industry benchmarks Aside from the de facto standard, there are of course various organisations developing benchmarks for AI accelerators (see: MLPerf, DawnBench, EEMBC, and others). While MLPerf has published inference results, Tate\u00e2\u0080\u0099s view is that this benchmark is too data center-oriented. He argues that this is exemplified by the following: in the single-stream scenario, which considers an edge device processing one image at a time (batch=1), the performance metric is 90th percentile latency. \u00e2\u0080\u009cAt the edge, I don\u2019t think customers want to know the 90th percentile, they want to know the 100th percentile. They want to know: what can you guarantee me?\u00e2\u0080\u009d Tate said, citing autonomous driving as an edge application where latency is critical. Performance on more complex image processing tasks such as object detection are more appropriate for comparing today\u00e2\u0080\u0099s high-end AI accelerators (Image: Flex Logix) Long tail latencies are a classic problem for systems that suffer from bus contention as information is transferred between many processor cores and the memory. While many of today\u00e2\u0080\u0099s devices use high bandwidth memory interfaces there is still a theoretical tail to the latencies while contention is possible. Flex Logix\u00e2\u0080\u0099 FPGA-based inference processor design has the exact same latency every time (something also claimed by Groq, though they are adamant their device is not an FPGA). \u00e2\u0080\u009cSince we\u2019re using the FPGA interconnect my co-founder invented at the core, there is a totally dedicated path from the memory through the multiply accumulators, to the logic for activation, and back to memory. So there\u2019s no contention: things just flow. We don\u2019t get a hundred percent utilization, but we get much higher utilization than all the other architectures,\u00e2\u0080\u009d said Tate. The Market Regarding the explosion in numbers of chip startups in this sector, Tate is sanguine about Flex Logix\u00e2\u0080\u0099 prospects. \u00e2\u0080\u009cWhen the chips come in and the software is run and they show the demos, and when you see the price and the power\u2026 very quickly, [companies] who aren\u2019t in the upper quartile will disappear,\u00e2\u0080\u009d he said. Tate\u00e2\u0080\u0099s prediction is that this sector can support 10 or 15 chip offerings, based on the different market segments (training, inference, data center, edge, ultra-low power, etc.). Offerings available today span multiple orders of magnitude in terms of compute power, so they don\u00e2\u0080\u0099t all compete directly with each other. \u00e2\u0080\u009cThere will be a giant culling of the herd in the next year or two,\u00e2\u0080\u009d says Tate, referring to the famous quote from Warren Buffett: \u00e2\u0080\u009cWhen the tide goes out, you can see who\u00e2\u0080\u0099s been swimming naked.\u00e2\u0080\u009d \u00a0 Related articles:  AI Inferencing Chip Targets Edge Servers Understanding MLPerf Benchmark Scores Benchmark Scores Reveal Who\u00e2\u0080\u0099s Winning the AI Inference Race \u00e2\u0080\u0098No-Show\u00e2\u0080\u0099 Groq Partially Unveils AI Architecture Benchmark Targets ML at the Edge      Share this:TwitterFacebookLinkedIn "}