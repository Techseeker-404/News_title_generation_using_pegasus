{"Author": "Junko Yoshida\u00a0", "Date": "05.26.2018", "Keywords": "Asic, Automotive, Digital, Industries, Microcontroller, Microprocessor, Microwave, Mission Critical, Radar, RF, Sensors, Transducers, Transportation", "Article": "  The National Transportation Safety Board\u00e2\u0080\u0099s preliminary report on Uber\u00e2\u0080\u0099s fatal crash in Arizona gave us a few insights, and surprises, about what went wrong with Uber\u00e2\u0080\u0099s AV. Least surprising was Uber\u00e2\u0080\u0099s decision to disable Volvo\u00e2\u0080\u0099s factory-equipped ADAS features, including the Automatic Emergency Brake (AEB). Phil Magney, Founder of VSI Labs, told us, \u00e2\u0080\u009cThis may be somewhat routine for robo-taxi development, as you don\u00e2\u0080\u0099t want the OEM ADAS systems to conflict with the Uber AV Stack.\u00e2\u0080\u009d What puzzled me, and others as well, is why Uber disabled its own AEB during testing on public roads. Of course, this assumes the Uber\u00e2\u0080\u0099s own AV stack had an AEB that worked properly. According to the NTSB report, Uber stated that its \u00e2\u0080\u009cdevelopmental self-driving system relies on an attentive operator to intervene if the system fails to perform appropriately during testing.\u00e2\u0080\u009d As we went through the NTSB preliminary report, two issues stood out. One is the immaturity of Uber\u00e2\u0080\u0099s AV software stack. Another is the absence of an Uber safety strategy in creating its AV testing platform. First, let\u00e2\u0080\u0099s talk about Uber\u00e2\u0080\u0099s AV software stack. We call it \u00e2\u0080\u009cimmature,\u00e2\u0080\u009d because it appears that too many false positives from its sensors worried Uber to the point the company trusted a human vehicle driver more than its own robotic car. Uber told NTSB, \u00e2\u0080\u009cemergency braking maneuvers are not enabled while the vehicle is under computer control, to reduce the potential for erratic vehicle behavior. The vehicle operator is relied on to intervene and take action.\u00e2\u0080\u009d Mike Demler, a senior analyst at The Linley Group, suspects that Uber\u00e2\u0080\u0099s sensor fusion, more accurately its software, \u00e2\u0080\u009cwas broken.\u00e2\u0080\u009d But the key information everyone had been looking for in the report was the data obtained from Uber\u00e2\u0080\u0099s self-driving system. The NTSB\u00e2\u0080\u0099s report said, \u00e2\u0080\u00a6the system first registered radar and LIDAR observations of the pedestrian about 6 seconds before impact, when the vehicle was traveling at 43 mph. As the vehicle and pedestrian paths converged, the self-driving system software classified the pedestrian as an unknown object, as a vehicle, and then as a bicycle with varying expectations of future travel path. At 1.3 seconds before impact, the self-driving system determined that an emergency braking maneuver was needed to mitigate a collision.    View of the self-driving system data playback at about 1.3 seconds before impact, when the system determined an emergency braking maneuver would be needed to mitigate a collision. Yellow bands are shown in meters ahead. Orange lines show the center of mapped travel lanes. The  purple shaded area shows the path the vehicle traveled, with the green line showing the center of that path.(Source: NTSB) "}