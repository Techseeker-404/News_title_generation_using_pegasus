{"Author": "EETimes\u00a0", "Date": "01.05.2017", "Keywords": "", "Article": " Video analytics are used to examine objects, people, situations, and more, and to then generate conclusions using deep learning and computer vision algorithms. Many implementations send footage over the cloud for processing, but is that such a good idea? The cloud is a useful and powerful resource for storing and processing data, but \u2014 as video cameras become more ubiquitous and more intelligent \u2014 the question of whether video analytics should be performed locally or remotely must be addressed. Issues of privacy, safety, security, and cost are strong grounds for the use of edge processing, meaning performing the video analysis onsite (i.e., edge analytics). With CES 2017 starting in just a couple of days at the time of this writing, a variety of cutting-edge prototypes will be showcased \u2014 what trend will take the crown? Every fraction of a second counts in ADAS One of the most pervasive uses of video analytics is in the automotive industry for advanced driver assistance systems (ADAS) in highly-automated vehicles (HAVs). The vision systems on HAVs use multiple cameras to identify traffic signals, vehicles, pedestrians, and other indicators, and then respond accordingly. This requires split-second response times and any delay is intolerable. So, relying on a remote server to process the data is not an option. Even if the communication speed is theoretically adequate, the data from each camera covering every angle of the vehicle, together with the growing number of camera-equipped vehicles, could stress available bandwidth, thereby causing an unacceptable delay.  Since most HAVs aren\u2019t fully autonomous and rely on a human driver, many systems include inward-directed cameras to assist with the handoff between the ADAS features and the human. One such driver monitoring system (DMS) is CoDriver by Jungo Connectivity, which has been named a CES 2017 Innovation Awards Honoree. This solution uses deep learning, machine learning, and computer vision algorithms to monitor the people inside the car and thus reduce crashes caused by drowsy or distracted drivers. According to ABI Research, camera-based DMSs like this one will reach 17.5 million annual shipments within a decade. Virtual assistants will be able to see everything Always-listening virtual assistants are already present in millions of homes. The next progression that will make virtual assistants even smarter and more helpful is the ability to see. An example of this is the always-seeing Koova camera robot, another 2017 CES Innovation Award Honoree. This small portable camera is capable of tracking movement, detecting and recognizing faces, and sending alerts or notifications according to customized settings. It allows the user to define specific activity zones for greater protection, as well as \u201cblockout zones,\u201d which are not to be monitored (presumably to address privacy concerns), but is that enough? With each advance in technology, privacy concerns arise. Continue reading on Embedded.com.      Share this:TwitterFacebookLinkedIn "}