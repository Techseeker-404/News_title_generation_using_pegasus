{"Author": "Junko Yoshida\u00a0", "Date": "01.04.2021", "Keywords": "ADAS, autonomous vehicles, Sensors", "Article": " Teledyne\u00e2\u0080\u0099s announcement Monday to acquire Flir Systems, a thermal imaging sensor company, in a $8 billion cash and stock deal, signaled a clear message to automotive technology suppliers: Thermal imaging is on the rise. Although somewhat unexpected, Teledyne\u00e2\u0080\u0099s move shouldn\u00e2\u0080\u0099t come as a surprise. The year 2020 taught us that neither autonomous vehicles (currently in road tests) nor consumer vehicles with advanced driver-assistance systems possess a level of \u00e2\u0080\u009ceyesight\u00e2\u0080\u009d that works in all weather conditions on all terrain all day long and in the dark. On one hand, AV developers have logged hours of driverless vehicles picking up and dropping off passengers in sunny Arizona, test-driving in Florida or tooling around downtown San Francisco (often limited to certain areas of the city at certain hours). On the other hand, conspicuously absent from the show are video clips of robocars braving fog, rain, snow, blizzards, low light and no light. Herein then lies the opportunity for new sensing modalities, including thermal imaging. Thermal image proponents, including Flir, Adasky and Foresight, have been proposing their technology as a \u00e2\u0080\u009cmust-have\u00e2\u0080\u009d in the ADAS and AV sensor suites. Some thermal imagers have been designed as an option into commercially available luxury cars, although not as a standard feature. Phil Magney, founder and president of VSI Labs, told us, \u00e2\u0080\u009cThe biggest use case for thermal cameras will be for pedestrian detection in low light conditions. Right now, the safety agencies are not testing for this yet, but once they do, then you will see a rapid adoption of thermal cameras for ADAS applications.\u00e2\u0080\u009d In a recent interview with EE Times, Chuck Gershman, CEO at Owl Autonomous Imaging, a startup based in Rochester, NY, said his company is joining the thermal imaging fray. Owl is introducing a \u00e2\u0080\u009cmonocular thermal imager producing high definition (HD) images with 3D ranging information,\u00e2\u0080\u009d he explained. Asked how it differs, Gershman pointed out that suppliers such as Flir, Adasky and Foresight offer VGA images, not HD. Flir and Adasky create 2D, not 3D, images. Foresight offers 3D with a four-camera stereo system. Owl claims that its 3D system is monocular. None of the developers (including Owl) touts its thermal imager as an end-all, be-all sensor for ADAS. However, they are challenging conventional wisdom on traditional sensor suites \u00e2\u0080\u0094 for which many believe that visible-light cameras fused with radar will suffice, perhaps with a lidar, if you can afford it. Thermal imaging promoters note that the beauty part of thermal is its ability to boost performance for ADAS (and AV) platforms in weather that includes dust, smog, fog, rain and snow. Who is Owl? Owl is a new entrant to the thermal imaging market for automotive applications. With 15 engineers, including several from Kodak who worked on the development of digital photography, Owl is preparing now for Series A funding. Citing the startup\u00e2\u0080\u0099s extensive \u00e2\u0080\u009chomework on imaging,\u00e2\u0080\u009d Gershman said, \u00e2\u0080\u009cWe didn\u00e2\u0080\u0099t take it lightly to go into this market.\u00e2\u0080\u009d At the long- and mid-wavelength infrared range (LWIR and MWIR) spectrum on which Owl\u00e2\u0080\u0099s thermal imager operates, its sensor is completely passive. As with other thermal imagers, it leverages the principle that all objects emit thermal energy. As Owl would explain it, \u00e2\u0080\u009cEverything has a unique thermal signature.\u00e2\u0080\u009d In contrast, other sensors need active light/energy sources. Visible-light cameras, for example, depend on light from the sun, streetlights, or headlights. Lidars emit laser light and use the reflected energy to measure time of flight. Radar sends radio signals and processes their bounceback. Not having to rely on a light source to detect objects is the killer edge for thermal imagers. However, the question becomes how well a particular thermal imager can classify objects, and capture their associated range and velocity. Owl claims it can do it all: detection, classification, range/velocity, day or night whatever the weather. Basic building blocks of Owl\u00e2\u0080\u0099s thermal imager Owl\u00e2\u0080\u0099s thermal imager comes in three blocks: 1) a monocular thermal imager, 2) an SoC that takes photonic information, converts photons to electrons and digitizes, and 3) a multi-aperture optical lens combined with CNN to create 3D ranging. Click the image above to enlarge. (Source: Owl) Owl claims its thermal imager can create depth/ranging information simply by using a monocular camera, rather than relying on stereovision. Thermal imagers with 3D depth map output To create ranging information, Owl has done a few things.\u00c2\u00a0 First, the multi-aperture lens in Owl\u00e2\u0080\u0099s monocular camera offers different perspectives of the same image. Using computational photography, Owl synthesizes a single image on every frame. Second, Owl applies CNN to determine distance. Rather than training CNN by using new data sets based on Owl\u00e2\u0080\u0099s thermal imaging sensor (collecting numerous data sets is time-consuming), Owl devised a way to train CNN using stereo video through a process called \u00e2\u0080\u009ctransfer learning.\u00e2\u0080\u009d As Gershman explained, \u00e2\u0080\u009cAt run time, we use both our multi-aperture optics coupled with our previously trained CNN to extract pixel disparity (which is the inverse of range) from a single image frame.\u00c2\u00a0 Additionally, we also generate pixel disparity, again the inverse of range, via a motion-based technique known as optical flow, which is a produced via intra-frame disparity measurements.\u00e2\u0080\u009d In the end, \u00e2\u0080\u009cIt is the combination of all of these techniques that enables Owl to generate range from a mono thermal camera.\u00e2\u0080\u009d Owl\u2019s video linked here demonstrates visually how the grayscale thermal video stream generated by a single passive sensor is overlaid by a colorized dense range map from Owl\u00e2\u0080\u0099s CNN software. (Source: Owl) The video on the left shows the industry standard for 2D visual imaging with classification boxes. The image on the right shows Owl\u2019s passive 3D thermal ranger with classification boxes. By overlaying Owl\u2019s AI software algorithms, Owl\u2019s grayscale thermal image is now colorized, and it generates range information from the camera. Both images use the standard Yolo v5 classification engine. Gershman stressed that the grayscale thermal video stream and 3D range map are \u00e2\u0080\u009csimultaneously generated,\u00e2\u0080\u009d then optically fused on the imager. In his opinion, applying ranging techniques to thermal \u00e2\u0080\u009chas never been done before.\u00e2\u0080\u009d Of course, as Gershman acknowledged, \u00e2\u0080\u009cRange estimation with multiple cameras such as stereo has been around for a long time. Further, range estimation with a mono camera using a \u00e2\u0080\u0098know reference\u00e2\u0080\u0099 is not really new.\u00e2\u0080\u009d By \u00e2\u0080\u0098know reference\u00e2\u0080\u0099, he means the pre-determined size of an object in the scene. \u00c2\u00a0\u00e2\u0080\u009cFor example, if I put a mono camera on the front of a train, and I know how wide the tracks are, I can calculate range by counting the number of pixels between the tracks, [because] the absolute width of the tracks never changes,\u00e2\u0080\u009d explained Gershman. However, Owl\u00e2\u0080\u0099s 3D thermal imager in contrast uses its CNNs to determine distance without reference to a known-size object. \u00e2\u0080\u009cThat is relatively new,\u00e2\u0080\u009d he noted. This was first demonstrated in academic literature in a September 2016 article entitled \u00e2\u0080\u009cUnsupervised Monocular Depth Estimation with Left-Right Consistency.\u00e2\u0080\u009d Owl has been continuously enhancing its CNN through iterations, according to Gershman. (Source: Owl) Owl\u2019s video shows that the thermal stream measures distance and classifies cyclists, vehicles, pedestrians, cars parked far to the side of the road. In contrast, the visual video fails to classify nearly all of these objects. The image above is a closer look at a couple of the critical objects of interest from the video. Note a frame with the two bicyclists (the image on top left) and a frame with the SUV and woman (the image on the bottom left) captured by the Owl\u2019s thermal imager (left), compared to the frames captured by the visual video camera (top and bottom right). While Owl has no intention to replace RGB cameras with its thermal imager, Gershman pointed out that his company\u00e2\u0080\u0099s thermal imager offers a much wider field of view. \u00e2\u0080\u009cYour RGB camera at night is limited in distance by the distance of your headlights \u00e2\u0080\u0093 it should have maybe 40, 50 meters total \u2014 and by the width of your headlights. Our intention is to build 105 to 110 degree wide field of view in a single camera.\u00e2\u0080\u009d Owl\u00e2\u0080\u0099s thermal imager vs. radar Many radar companies lately are talking up their 3D, 4D imaging sensors. While acknowledging some improvements, Gershman believes that radars still produce very low-resolution images. In debating resolution, there is a simple litmus test for 4D imaging radar. Assume a large car enters its field of view. Then, put a person next to the car.\u00c2\u00a0 The car is obviously bigger and taller. The problem with radar is that it sees a car, but not a person. As radar emits radio signals and processes the return signal, it favors the car because the bigger the object, the more energy comes back. Likewise, more metal means more energy bouncing back. The lower energy response coming back from a smaller, softer object gets lost. This is why radar is often described as \u00e2\u0080\u009cnoisy,\u00e2\u0080\u009d said Gershman. Compared to radar, Owl\u00e2\u0080\u0099s thermal imager produces higher resolution images with less noise. Lidar vs. Owl\u00e2\u0080\u0099s thermal imager Lidar and Owl\u00e2\u0080\u0099s thermal imager are both looking for depth information. Magney is still skeptical about the quality of Owl\u00e2\u0080\u0099s 3D information compared to lidars. He called lidar ranging \u00e2\u0080\u009cdead accurate,\u00e2\u0080\u009d because it uses time of flight to calculate range. In contrast, he suggested, Owl\u00e2\u0080\u0099s thermal imager is doing an \u00e2\u0080\u009cestimate.\u00e2\u0080\u009d This circles back to the original question: What\u00e2\u0080\u0099s the real advantage of Owl\u00e2\u0080\u0099s thermal imager over lidar? Owl\u00e2\u0080\u0099s Gershman noted, \u00e2\u0080\u009cLidar produces a sparse cloud, which makes detection and classification of smaller objects at longer range unreliable.\u00e2\u0080\u009d He added, \u00e2\u0080\u009cAs a rule of thumb a LiDAR point is generally accurate to about 10cm which is good.\u00c2\u00a0However, that is based on a point being returned.\u00c2\u00a0 As LiDAR produces a sparse cloud objects at longer range may not be hit and thereby go undetected.\u00e2\u0080\u009d In contrast, Owls\u00e2\u0080\u0099 dense point cloud, said Gershman, provides range information for objects large and small even at long range, providing enough response for Automatic Emergency Breaking to prevent contact with pedestrians, cyclists and animals. However, as Gershman stressed, the point of offering a 3D monocular thermal imaging camera is not to replace cameras or radars. \u00e2\u0080\u009cThe goal is to complement them,\u00e2\u0080\u009d he said. Why OEMs are reluctant? Despite the obvious advantage of thermal imaging (all weather, low and no light conditions), \u00e2\u0080\u009cOEMS have been reluctant,\u00e2\u0080\u009d Magney pointed out. \u00e2\u0080\u009cFirst of all, it is expensive.\u00e2\u0080\u009d The cost argument also applies to carmakers reluctant to add lidars to ADAS. Owl is talking turkey with some forty companies, including tier ones and OEMs who are already piloting with Owl\u00e2\u0080\u0099s prototypes, according to Gershman. He said, \u00e2\u0080\u009cWe\u2019ll be kicking off a number of additional pilots in the first half of 2021. Owl\u00e2\u0080\u0099s new, improved version is scheduled to come out in mid-2021. Noting that this new iteration will be cheaper, Gershman said Owl expects to sell a monocular thermal imaging camera \u00e2\u0080\u009cat $200 in volume between 2023 and 2024.\u00e2\u0080\u009d The second reason why a thermal imager makes OEMs hesitate, Magney noted, is the difficulty of installation. \u00e2\u0080\u009cYou cannot mount a thermal camera behind the windscreen.\u00c2\u00a0 The optical properties of glass are incompatible with thermal imagers.\u00c2\u00a0 So this means you have to find a new place to mount it. This usually means the roof.\u00e2\u0080\u009d Gershman concurred. \u00e2\u0080\u009cIt can\u00e2\u0080\u0099t be behind the windshield. The windshield glass will either be lowered slightly, or the roof line raised around the camera.\u00e2\u0080\u009d He pointed out, however, that alternatively Owl\u00e2\u0080\u0099s thermal imaging camera \u00e2\u0080\u0093 which fits in the palm of a hand \u00e2\u0080\u0093 can fit inside a headlight.\u00c2\u00a0\u00e2\u0080\u009cHeadlight plastic can transmit thermal.\u00e2\u0080\u009d     Share this:TwitterFacebookLinkedIn "}