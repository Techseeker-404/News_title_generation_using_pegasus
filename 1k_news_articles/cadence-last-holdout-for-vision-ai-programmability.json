{"Author": "Junko Yoshida\u00a0", "Date": "04.11.2018", "Keywords": "Computers And Peripherals, Consumer Electronics & Appliances, Digital, DSP, Handsets, Mobile, Semiconductors, SoC, Video", "Article": "  Cadence Design Systems, Inc. might have found the secret recipe for success in an increasingly hot AI processing-core market by promoting a suite of DSP cores that accelerate both embedded vision and artificial intelligence. The San Jose-based company is rolling out on Wednesday (April 11) the Cadence Tensilica Vision Q6 DSP. Built on a new architecture, the Vision Q6 offers faster embedded vision and AI processing than its predecessor, Vision P6 DSP, while occupying the same floorplan area as that of P6. The Vision Q6 DSP is expected to go into SoCs that will drive such edge devices as smartphones, surveillance cameras, vehicles, AR/CR, drones, and robots. The new Vision Q6 DSP is built on Cadence\u00e2\u0080\u0099s success with Vision P6 DSP. High-profile mobile application processors such as HiSilicon\u00e2\u0080\u0099s Kirin 970 and MediaTek\u00e2\u0080\u0099s P60 both use the Vision P6 DSP core. Among automotive SoCs, Dream Chip Technologies is using four Vision P6 DSPs. Geo Semiconductor\u00e2\u0080\u0099s GW5400 camera video processor has adopted Vision P5 DSP. Mike Demler, senior analyst, The Linley Group, told EE Times that where Vision Q6 DSP differs from its competitors is \u00e2\u0080\u009cits multi-purpose programmability.\u00e2\u0080\u009d Among all computer-vision/neural-network accelerators on the market today, Demler noted, \u00e2\u0080\u009cCadence is the last holdout for a completely programmable multipurpose architecture. They go for flexibility over raw performance.\u00e2\u0080\u009d Demler added that Vision Q6 DSP is \u00e2\u0080\u009ccomparable to the earlier Ceva XM4 and XM6, also DSP-based. But those cores add a dedicated multiplier-accumulator (MAC) array to accelerate convolution neural networks (CNNs).\u00e2\u0080\u009d He observed that Synopsys started with a CPU-MAC combination in its EV cores, but moved on to a CPU-DSP-MAC accelerator combo in the EV6x. Ceva went to a more special-purpose accelerator architecture in NeuPro, which looks more like Google\u00e2\u0080\u0099s TPU. Demler said, \u00e2\u0080\u009cCeva\u00e2\u0080\u0099s NeuPro has much higher neural-network performance, but so do most of the other IP competitors. It\u00e2\u0080\u0099s a growing list now with Nvidia\u00e2\u0080\u0099s open-source NVDLA, Imagination, Verisilicon, Videantis, and others.\u00e2\u0080\u009d Vision + AI strategy  Thus far, Cadence is sticking to its original strategy of vision + AI on a single DSP core. Demler believes that \u00e2\u0080\u009cSoC providers are seeing an increased demand for vision and AI processing to enable innovative user experiences like real-time effects at video-capture frame rates.\u00e2\u0080\u009d Indeed, Lazaar Louis, senior director of product management and marketing for Tensilica IP at Cadence, explained that more embedded vision applications have begun leveraging AI algorithms. Meanwhile, some AI functions improve when better vision processing comes first, he added. AI-based face detection is an example. By capturing a face in varying multiple resolutions first, AI can detect it better. Meanwhile, to offer a vision feature like \u00e2\u0080\u009cbokeh\u00e2\u0080\u009d with a single camera, AI first performs segmentation, followed by blurring and de-blurring in the vision operation. Both applications demand the mix of vision and AI operations, and Cadence\u00e2\u0080\u0099s DSPs can put both operations in the camera pipeline, explained Louis. More significantly, though, Cadence is hoping to use its well-proven vision DSP as a \u00e2\u0080\u009cTrojan horse\u00e2\u0080\u009d to open the door to design wins in present and future SoCs expected to handle more AI processing, acknowledged Louis.  Cadence DSP Camera Processing Pipeline (Source: Cadence)   On one hand, Cadence has both Vision P6 DSP and Vision Q6 DSP, designed to enable general-purpose embedded vision and more vision-related on-device AI applications. On the other, Cadence has a standalone AI DSP core, the Vision C5, which offers more \u00e2\u0080\u009cbroad-stroke AI,\u00e2\u0080\u009d according to Louis, for always-on neural network applications. While the Vision P6 and the Vision Q6 are used for applications requiring AI performance ranging from 200 to 400 GMAC/sec, the Vision Q6 DSP can be paired with the Vision C5 DSP for applications requiring greater than 384-GMAC/sec AI performance, according to Cadence. Q6 advantages  The new Q6 comes with a deeper, 13-stage processor pipeline and system architecture designed for use with large local memories. It enables the Vision Q6 DSP to achieve 1.5-GHz peak frequency and 1-GHz typical frequency at 16 nm in the same floorplan area as the Vision P6 DSP, according to Cadence. As a result, designers using the Vision Q6 DSP can develop high-performance products that meet increasing vision and AI demands and power-efficiency needs. Vision Q6 DSP offers 13-Stage Pipeline (Source: Cadence)  But what sorts of applications are driving the vision and AI operations to run faster? "}