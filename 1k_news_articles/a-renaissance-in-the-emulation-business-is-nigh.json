{"Author": "Jean-Marie Brunet and Lauro Rizzatti\u00a0", "Date": "12.16.2019", "Keywords": "Fpga", "Article": " Hardware emulation was conceived in the mid-1980s by a few pioneers who identified an opportunity for field programmable gate-array (FPGA), then a new type of device. They envisioned building prototypes of digital designs by interconnecting several FPGAs in large arrays before the actual silicon was returned by the foundry. Two companies emerged with working solutions, Quickturn Design Systems and IKOS Systems, giving birth to a new industry. For the first 10 years, hardware emulation remained a niche business with a questionable future. While the concept was promising, the actual implementation was a minefield of issues \u00e2\u0080\u0094 and its deployment a nightmare \u00e2\u0080\u0094 requiring technical experts with multiple degrees in various disciplines. It took years to improve and ease the deployment. All along, brilliant engineers devised solutions to alleviate the problems via software enhancements and/or hardware architectural innovations. Fast forward. The hardware emulation market today is thriving, boosted by state-of-the-art systems offered by the three major electronic design automation (EDA) providers, Synopsys, Cadence and Mentor, a Siemens Business. A look at the revenue generated by hardware emulation products starting in 1995 offers some patterns to predict the future. See Table I. The chart reveals four peaks in revenue, the last one still in the making. The first peak occurred in the mid-1990s when the two dominant players Quickturn Design Systems and IKOS Systems launched new versions of their FPGA-based emulators and new startups entered the market. Among them, Meta System, a company in France that launched an emulator based on a custom architecture. All the players cumulatively pushed revenue up. In the following few years, a long trail of patent litigations among the emulation players and market consolidation weakened the spending in emulation products. The dot.com euphoria leading to the year 2000 sparked activity in the electronics business, pulling along emulation revenue that recorded a second peak. When the dot.com bubble burst in 2000, emulation revenue crashed. By 2002, only two established players, Cadence and Mentor Graphics, and startup Emulation Verification Engineering (EVE) competed for the business. In the ensuing years, the market remained flat. Internal reorganizations following consolidations, late new product launches, and a sluggish market contributed to the lack of growth. In the second half of the first decade of 2000, two trends altered the design landscape. While hardware design sizes grew to the point of defeating the capacity of hardware description language (HDL) simulators, the exploding embedded software content in system-on-chip (SoC) designs demanded faster verification engines than HDL simulators. The new breed of designs consisted of hardware platforms layered with embedded software content. Hardware emulation became the only solution to meet the demand posed by both trends leading to impressive revenue growth until 2013. In subsequent years, two independent events contributed to the decline of emulation revenue. The acquisition of EVE by Synopsys slowed its market momentum, and late introductions of new emulators by the other two vendors hastened the overall drop in emulation revenue. Never sitting idle and driven by the trust in the technology, all three vendors invested in their emulation businesses, reorganized their business units and developed new products. Three years later, within one or two years from one another, all three launched new emulation platforms. The market started to record another remarkable revenue growth. Today, the emulation technology is a necessity for the verification/validation of modern designs in most vertical markets, from processors/graphics to communication, networking, storage, wireless and automotive. The emerging fields of 5G and artificial intelligence (AI) could not progress without hardware emulation. Epitomized by the creation of autonomous vehicles, the automotive industry coined the new expression system of systems (SoS) to include the convergence of technologies from diverse industries such as electronic, mechanical, and thermal. SoS designs need hardware emulation. A breakthrough occurred with the adoption of virtualization, namely, the ability to model a real-world environment via a software-based equivalent setup. Via virtualization, a modern emulation platform can be effectively used. Indeed, it is the only solution for exhaustive hardware/software system-level validation, including power/performance verification and validation. It can estimate power consumption of an SoC design running real-world applications as opposed to executing ad-hoc testbenches. Its uniqueness is its ability to validate power/performance tradeoffs running state-of-the-art machine learning (ML)/AI frameworks or payloads such as Caf\u00c3\u00a9 with MLPerf benchmarks. After a few decades that recorded higher revenue than software-based simulation systems, revenue of hardware-assisted verification platforms \u00e2\u0080\u0093 including emulators and FPGA-based prototypes \u00e2\u0080\u0093 now tops the list of verification engines. The trend will continue and never fall back. In fact, it is reasonable to predict that by the end of 2019, when revenue for Q3/Q4, 2019 will be released by the Electronic System Design (ESD) Alliance, hardware-assisted verification revenue will break through $600 million. In the coming years, the emulation technology and products will continue to evolve and improve, and deployment will expand beyond the traditional electronic industry boundary. The result will ensure that annual revenue will eventually hit $1 billion. \u00e2\u0080\u0094 Jean-Marie Brunet is senior marketing director for the Mentor Emulation Division, Mentor, a Siemens Business, and Lauro Rizzatti is principal at Rizzatti Marketing Consulting.     Share this:TwitterFacebookLinkedIn "}