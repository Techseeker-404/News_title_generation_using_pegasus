{"Author": "Junko Yoshida\u00a0", "Date": "08.31.2017", "Keywords": "Asic, Audio, Automotive/Transportation, Business Topics, Cloud Computing, Computers And Peripherals, Consumer Electronics & Appliances, Digital, DSP, FPGA/PLD/CPLD, Funding, Graphics, Handsets, Industries, Memory/Storage, Microcontroller, Microprocessor, Mission Critical, Mobile, Servers, Solid State, Supercomputers, Video, Video Processor, Wearables", "Article": " MADISON, Wis. \u00e2\u0080\u0094\u00c2\u00a0Ren Wu, formerly a distinguished scientist at Baidu, has pulled a new AI chip company out of his sleeve, called NovuMind, based in Santa Clara, Calif. In an exclusive interview with EE Times, Wu discussed the startup\u00e2\u0080\u0099s developments and what he hopes to accomplish.  Established two years ago, with 50 people, including 35 engineers working in the U.S. and 15 in Beijing, NovuMind is testing what Wu describes as a minimalist approach to deep learning. Rather than designing general-purpose deep-learning chips like those based on Nvidia GPUs or Cadence DSPs, NovuMind has focused exclusively on developing a deep learning accelerator chip that \u00e2\u0080\u009cwill do inference very efficiently,\u00e2\u0080\u009d Wu told us. NovuMind has designed an AI chip that uses only very small (3\u00d73) convolution filters. This approach might seem counterintuitive at a time when the pace of artificial intelligence has accelerated almost dizzyingly. Indeed, many competitors concerned with yet-to-emerge AI algorithms have set their sights on chips that are as programmable and powerful as possible. [Sponsored Teardown: See inside Schneider variable speed drives.]  In contrast, NovuMind is concentrating on \u00e2\u0080\u009conly the core of the neural network that is not likely to change,\u00e2\u0080\u009d said Wu. He explained that 5\u00d75 convolution can be done by stacking two 3\u00d73 filters with less computation, and 7\u00d77 is possible by stacking three. \u00e2\u0080\u009cSo, why bother with those other filters?\u00e2\u0080\u009d The biggest problem with architectures like DSP and GPU in deep-learning accelerators on edge devices is \u00e2\u0080\u009cthe very low utilization\u00e2\u0080\u009d of their processors, Wu said. NovuMind solves \u00e2\u0080\u009cthis efficiency issue by using unique tensor processing architecture.\u00e2\u0080\u009d Wu calls NovuMind\u00e2\u0080\u0099s idea \u00e2\u0080\u0094\u00c2\u00a0focused on the minimum set of convolutions in a neural network \u00e2\u0080\u0094\u00c2\u00a0\u00e2\u0080\u009caggressive thinking.\u00e2\u0080\u009d\u00c2\u00a0 He said the mission of his new chip is to embed power-efficient AI everywhere. The company\u00e2\u0080\u0099s first AI chip \u00e2\u0080\u0094\u00c2\u00a0designed for prototyping \u00e2\u0080\u0094\u00c2\u00a0is expected to be taped out before Christmas. Wu said by February next year he expects applications to be up and running on a 15 teraflops of performance (ToP) chip under 5 watts. A second chip, designed to run under a watt, is due in mid-2018, he added. NovuMind\u2019s new chip will support Tensorflow, caffe and torch models natively. The endgame of Wu\u00e2\u0080\u0099s AI chip is to enable a tiny Internet-connected \u00e2\u0080\u009cedge\u00e2\u0080\u009d device to not only \u00e2\u0080\u009csee\u00e2\u0080\u009d but \u00e2\u0080\u009cthink\u00e2\u0080\u009d (and recognize what it sees), without hogging the bandwidth going back to the data center. Wu calls it the Intelligent Internet of Things (I\u00c2\u00b2oT).  For Wu, who hasn\u00e2\u0080\u0099t sought much publicity in the last few years, NovuMind presents, in a way, an opportunity for redemption. Two years ago, Wu was let go by Baidu, after the Chinese search giant was disqualified from the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2015. Wu subsequently denied wrongdoing in what was then labeled as \u00e2\u0080\u009cMachine learning\u00e2\u0080\u0099s first cheating scandal.\u00e2\u0080\u009d Speaking with EE Times, he declined to discuss that event, other than noting, \u00e2\u0080\u009cI think I was set up.\u00e2\u0080\u009d In today\u00e2\u0080\u0099s hotly pursued market of deep-learning accelerators for edge devices, NovuMind is forging ahead. After raising $15.2 million in series A funding in December 2016, NovuMind is about to begin a second round of fundraising, said Wu. \u00e2\u0080\u009cThat\u00e2\u0080\u0099s why I am in Beijing now,\u00e2\u0080\u009d he told me during a phone interview. Next page: 3D tensor operation      Share this:TwitterFacebookLinkedInNext Page "}