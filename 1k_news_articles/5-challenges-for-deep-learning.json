{"Author": "Shriram Ramanathan\u00a0", "Date": "07.31.2018", "Keywords": "Advanced Technology, Cloud Computing, Communications And Networking Systems Or Equipment, Computers And Peripherals, Digital, Graphics, Hardware Development, Market Research, Microprocessor, Networking, Research & Development, Semiconductors, Servers, Software", "Article": "  Deep learning ranked #2 among nearly 2,700 technologies in healthcare, materials, energy and digital transformation in a machine learning-based analysis of innovation data. The study, conducted by Lux Research, explored areas including patents and VC funding. The technology has become very popular in image recognition, going beyond tagging pictures in social media to use cases like autonomous driving, quality control in manufacturing and medical imaging. Engineers are now unleashing the power of deep learning in applications as diverse as cybersecurity, drug design, voice recognition, chip design and optimizing manufacturing operations. However, data scientists must overcome several challenges before deep learning can find widespread adoption. First, they need to find and process massive datasets for training. While this is not a problem for consumer applications where large amounts of data are easily available, copious amounts of training data are rarely available in most industrial applications. Once the data sets are in hand, using them to train deep-learning networks can require days on big clusters of CPUs and GPUs.graphics processing units. Emerging techniques like transfer learning and generative adversarial networks show some promise with regard to overcoming this challenge. Second,  one of the reasons deep learning works so well is the large number of interconnected neurons, or free parameters, that allow for capturing subtle nuances and variations in data. However, this also means that it is harder to identify hyperparameters, parameters whose values need to be fixed before training. The process is more art than science. There is also the danger of overfitting data, especially when the number of parameters greatly exceeds the number of independent observations. Third, wenoted in a recent webinar that several drivers, such as latency and privacy, will usher in an era of edge computing. Large deep learning networks, while very powerful, are difficult to implement on the edge because of their sheer size. Moreover, deep learning networks require a lot of time for training, thereby making it very hard to quickly retrain models on the edge using newly available information. Fourth, due to the sheer number of layers, nodes, and connections, it is difficult to understand how deep learning networks arrive at insights. While this may not be that important in applications like tagging photos on social media, understanding the decision-making process becomes very important in mission-critical applications like predictive maintenance or clinical decision-making. Researchers including some working for the U.S. military are trying to develop \u00e2\u0080\u009cexplainable AI\u00e2\u0080\u009d to address this issue. Finally, deep-learning networks are highly susceptible to the butterfly effect\u2013small variations in the input data can lead to drastically different results, making them inherently unstable. This instability also is opening new attack surfaces for hackers. In what are known as adversarial attacks, researchers have shown that, just by adding an imperceptible amount of noise, it is possible to fool deep learning networks into arriving at completely incorrect insights \u00e2\u0080\u0093 all without even accessing the system. \u2013Shriram Ramanathan is a senior analyst covering artificial intelligence and big data analytics at Lux Research.  "}